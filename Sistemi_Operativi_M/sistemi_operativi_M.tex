\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{listings}
\usepackage{parcolumns}
\usepackage{graphicx}
\usepackage[usenames,dvipsnames,svgnames,table]{xcolor}

\setlength\parindent{0pt}

\lstset{language=Java}
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
tabsize = 4,
showstringspaces = false,
numbers = left, 
commentstyle = \color{green},
keywordstyle = \color{blue}, 
stringstyle = \color{red}, 
rulecolor = \color{black}, 
basicstyle = \small \ttfamily ,
breaklines = true,
numberstyle = \tiny,
frame = shadowbox,
postbreak = \raisebox{0ex}[0ex][0ex]{\ensuremath{\hookrightarrow}}
}

\lstset{style=mystyle}

\title{Sistemi Operativi M}
\author{Federico Andrucci}
\date{September 2021}

\begin{document}

\maketitle
\tableofcontents

\newpage

\section{Virtualizzazione}

Virtualizzare un sistema (hardware e software) significa presentare all'uilizzatore una visione delle risorse del sistema diversa da quella reale.
Ciò è possibile introducendo un \textbf{livello di indirezione} tra la vista logica e quella fisica delle risorse.

Quindi l'obiettivo della virtualizzazione è quello di disaccoppiare il comportamento delle risorsedi un calcolatore dalla loro realizzazione fisica. 
Quindi apparendo diverse da quelle effettive della macchina. Il software che si occupa di virtualizzare in parole semplici divide le risorse reali nel numero di macchine virtuali necessarie. 
Quindi ogni macchina virtuale avrà la sua CPU, GPU, RAM, ecc...

Esmpi di virtualizzazione:
\begin{itemize}
    \item \textbf{Virtualizzazione a livello di processo:} i sistemi multitasking permettono l'esecuzione contemporanea di più processi, ognuno dei quale dispone 
    di una macchina virtuale dedicata. Questo tipo di virtualizzazione viene realizzata dal kernel del sistema operativo.
    \item \textbf{Virtualizzazione della memoria:} in presenza di memoria virtuale, ogni processo vede uno spazio di indirizzamento di dimensioni indipendenti dallo spazio fisico effettivamente a dispozione. Anche questa virtualizzaione è realizzata dal kernel.
    \item \textbf{Astrazione:} un oggetto astratto (risorsa virtuale) è la rappresentazione semplificata di un oggetto (risortsa fisica), quindi esibendo le 
    proprietà significative per l'utilizzatore e nascondendo i dettagli realizzativi non importanti
\end{itemize}

\subsection{Virtualizzazione di un Sistema di Elaborazione}
Tramite la virtualizzazione una singola piattaforma hardware viene condivisa da più elaboratori virtuali, ognuno gestito da un proprio sistema operativo.
Il disaccoppiamento viene realizzato dal \textbf{Virtual Machine Monitor (VMM)}, il cui compito è quello di consentire la condivisione da parte di più macchine 
virtuali di una singola piattaforma hardware.

Quindi il \textbf{VMM} è il \textbf{mediatore unico} nelle interazioni tra le macchine virtuali e
l'hardware, il quale garantisce: \textbf{isolamento tra le VM} e \textbf{stabilità del sistema}.

\subsection{Tecniche del VMM}
\subsubsection{Emulazione}
L'emulazione è l'insieme di tutti quei meccanismi che permettono l'esecuzione di un programma compilato su un determiato sistema di girare su un qualsiasi altro sistema differente da quello nel quale è stato compilato.
Quindi vengono emulate interamente le singole istruzioni dell'architettura ospitata.

I vantaggi dell'emulazione sono l'interoperabilità tra ambienti eterogenei, mentre gli svantaggi sono le ripercussioni sulle performances.

\vspace{5mm}
Esistono principalmente due tecniche di emulazione: \textbf{interpretazione} e \textbf{ricompilazione dimanica}.

\vspace{5mm}
\textbf{Interpretazione}:

L'interpretazione si basa sulla lettura di ogni singola istruzione del codice macchina che deve essere eseguito e sulla esecuzione di più istruzioni sull'host virtualizzante.
Produce un sovraccarico elevento in quanto potrebbero essere necessarie molte istruzioni dell'host per interpretare una singola istruzione sorgente.

\vspace{5mm}
\textbf{Compilazione dinamica}:

Invece di leggere una singola istruzione del sistema ospitato, legge interi blocchi di codice, vengono analizzati, tradotti per la nuova architettura, ottimizzati e messi in esecuzione.
Il vantaggio in termini prestazionali rispetto all'interpretazione è notevolmente maggiore.

Ad esempio parti di codice utilizzati frequentemente vengono bufferizzati nella cache per evitare di doverli ricompilare in seguito.


..
..
..


\subsection{Realizzaione del VMM}
\textbf{Requisiti di Popek e Goldberg del 1974}:

\begin{itemize}
    \item \textbf{Ambiente di esecuzione per i programmi sostanzialmente identico a quello della macchina reale}: Gli stessi programmi che eseguono nel sistema non virtualizzato possono essere eseguiti nelle VM
    senza modifiche e problemi.
    \item \textbf{Garantire un'elevata efficienza nell'esecuzione dei programmi}: Il VMM deve permettere l'esecuzione diretta delle istruzioni impartite dalle macchine virtuali, quindi le istruzioni non 
    privilegiate vengono eseguite direttamente in hardware senza coinvolgere il VMM
    \item \textbf{Garantire la stabilità e la sicurezza dell'intero sistema}: Il VMM deve sempre rimanere sempre nel pieno controllo delle risorse hardware, e i programmi in  esecuzione nelle macchine virtuali non possono 
    accedere all'hardware in modo privilegiato
\end{itemize}

\textbf{Parametri e classificazione}
\begin{itemize}
    \item \textbf{Livello} nel quale è collocato il VMM:
    \begin{itemize}
        \item \textbf{VMM di sistema}: eseguono direttamente sopra l'hardware del elaboratore (vmware, esx, xen, kvm)
        \item \textbf{VMM ospitati}: eseguiti come applicazioni sopra un S.O. esistente (parallels, virtualbox)
    \end{itemize}
    \item \textbf{Modalità di dialogo}: per l'accesso alle risorse fisiche tra le macchine virtuali ed il VMM:
    \begin{itemize}
        \item \textbf{Virtualizzazione pura} (vmware): le macchine virtuali usano la stessa interfaccia dell'architettura fisica
        \item \textbf{Paravirtualizzazione} (xen): il VMM presenta un'interfaccia diversa da quella dell'architettura HW
    \end{itemize}
\end{itemize}

\subsubsection{Ring di protezione}

La CPU prevede due livelli di protezione: \textbf{supervisore o kernel (0)} e \textbf{utente ($<$0)}.

Ogni ring corrisponde a una diversa modalità di funzionamento del processore:
\begin{itemize}
    \item a livello 0 vengono eseguite le istruzioni privilegiate della CPU
    \item nei ring di livello superiore a 0 le istruzioni privilegiate non vengono eseguite
\end{itemize}

Alcuni progrmmi sono progettati per eseguire nel ring 0, ad esempio il Kernel del S.O. infatti è l'unico componente che ha pieno controllo dell'hardware.

\vspace{3mm}
\textbf{VMM (vmm di sistema)}

In un sistema virtualizzato il VMM deve essere l'unica componente in grado di mantenere il controllo completo dell'hardware. Infatti solo il VMM opera nello stato supervisore, 
mentre il S.O. e le applicazioni eseguono in un ring di livello superiore.

Sorgono però due problemi:
\begin{itemize}
    \item \textbf{Ring deprivileging}: il s.o. della macchina virtuale esegue in un ring che non gli è proprio
    \item \textbf{Ring compression}: se i ring utilizzati sono solo 2, applicazioni e s.o. della macchina virtuale eseguono allo stesso livello: 
    scarsa protezione tra spazio del s.o. e delle applicazioni.
\end{itemize}

\subsubsection{Ring Deprivileging}
Con Ring Deprivilenging si indica una situazione nel quale l'esecuzione di istruzioni privilegiate richieste dal sistema operativo nell'ambiente guest non
possono essere eseguite in quanto richiederebbero un ring 0, ma il kernel della macchina virtuale esegue in un ring di livello superiore (foto telefono 1)

Una possibile prima soluzione è il \textbf{Trap \& Emulate}: nel quale se il guest tenta di eseguire un'istruzione privilegiata

\begin{itemize}
    \item la CPU notifica un'eccezione al VMM (\textbf{trap}) e gli trasferisce il controllo
    \item il VMM controlla la correttezza dell'operazione richiesta e ne emula il comportamento (\textbf{emulate})
\end{itemize}

Quindi in poche parole la CPU notifica e delega al VMM il controllo e l'esecuzione dell'istruzione privilegiata.

Esempio:

Il guest tenta di disabilitare le interruzioni (popf), se la richiesta della macchina virtuale fosse eseguita direttamente sulla CPU sarebbero disabilitati
tutti gli interrupt di sistema e quindi il VMM non potrebbe riottenere il controllo. Invece, con Trap\&Emulate riceve la notifica di tale richiesta e ne emula
il comportamento sospendendo gli interrupt solamente per la macchina virtuale richiedente.

\vspace{3mm}
\textbf{Supporto HW alla virtualizzazione}

L'archietettura della CPU si dice \textbf{naturalmente virtualizzabile} se e solo se prevede l'invio di trap al VMM per ogni istruzione privilegiata invocata da un
livello di protezione differente dal quello del VMM.

Se la CPU è naturalmente virtualizzabile viene implementato il trap\&emulate, altrimenti, se non è virtualizzabile vi sono 2 possibilità: \textbf{Fast Binary Translation} e 
\textbf{Paravirtualizzazione}.

\subsubsection{Fast Binary Translation}
Il VMM scansiona dinamicamente il codice dei sistemi operativi guest prima dell'esecuzione per sostituire a run time i blocchi contenenti istuzioni privilegiate
in blocchi equivalenti dal punto di vista funzionale e contenenti chiamate al VMM. Inoltre i blocchi tradotti sono eseguiti e conservati in cache per eventuali
riusi futuri. (SISTEMARE)

(immagine slide 33)

Il principale limite della Fast Binary Translation è che la traduzione dinamica è molto costosa. Però, con questa tecnica, ogni macchina virtuale è una esatta
copia della macchina fisica, con la possiblità di installare gli stessi s.o. di architetture non virtualizzate.

\subsubsection{Paravirtualizzazione}
Il VMM (hypervison) offre al sistema operativo guest un'interfaccia virtuale (ovviamente differente da quello hardware del processore) chiamata **hypercall API**
alla quale i s.o. guest devono rifersi per avere accesso alle risorse (system call).

Queste Hypercall API permettono di:
\begin{itemize}
    \item richiedere l'esecuzione di istruzioni privilegiate, senza generare un interrupt al VMM
    \item i kernel dei s.o. guest devono quindi essere modificati per avere accesso all'interfaccia del particolare VMM
    \item la struttura del VMM è semplificata perchè non deve più preoccuparsi di tradurre dinamicamente i tentativi di operazioni privilegiate dei s.o. guest
\end{itemize}

Le prestazioni rispetto alla Fast Binary Translation sono notevolmente superiori, però ovviamente c'è una necessità di porting dei dei s.o. guest (non sempre facile).

(aggiungere protezione processore)


\newpage

\section{La protezione nei Sistemi Operativi}

\textbf{Sicurezza}: riguarda l'insieme delle tecniche per regolamentare l'accesso degli utenti al sistema di elaborazione. La sicurezza impedisce accessi
non autorizzati al sistema e i conseguenti tentativi dolosi di alterazione e distruzione di dati.

\vspace{3mm}
\textbf{Protezione}: insieme di attività volte a garantire il controllo dell'accesso alle risorse logiche e fisiche da parte degli utenti autorizzati
all'uso di un sistema di calcolo.

La sicurezza mette a disposizione meccanismi di **identificazione, autenticazione, ...**

Per rendere un sistema sicuro è necessario stabilire per ogni utente autorizzato:
\begin{itemize}
    \item quali siano le risore alle quali può accedere
    \item con quali operazioni può accedervi
\end{itemize}

Tutto ciò è stabilito dal sistema di protezione attraverso delle tecniche di controllo dell'accesso.

In un sistema il controllo degli accessi si esprime tramite la definizione di tre livelli concettuali:
\begin{itemize}
    \item modelli
    \item politiche
    \item meccanismi
\end{itemize}

\vspace{3mm}
\textbf{Modelli:}

Un modello di protezione definisce i soggetti, gli oggetti e i diritti d'accesso:
\begin{itemize}
    \item \textbf{oggetti}: costituiscono la parte passiva, cioè le risorse fisiche e logiche alle quali si può accedere e su cui si può operare.
    \item \textbf{soggetti}: rappresentano la parte attiva di un sistema, cioè le eintità che possono richiedere l'accesso alle risorse (utenti e processi)
    \item \textbf{diritti d'accesso}: sono le operazioni con le quali è possibile operare sugli oggetti
\end{itemize}

(Un soggetto può avere diritti d'accesso sia per gli oggetti che per gli altri soggetti)

Ad ogni soggetto è associato un \textbf{dominio di protezione}, che rappresenta l'ambiente di protezione nel quale il soggetto esegue. Quindi il dominio
indica i diritti d'accesso posseduti dal sogetto nei confronti di ogni risorsa.

Un dominio di protezioen è unico per ogni soggetto, mentre un processo può eventualmente cambiare dominio durante la sua esecuzione.

\vspace{3mm}
\textbf{Politiche:}

Le \textbf{politiche di protezione} definiscono le regole con le quali i soggetti possono accedere agli oggetti
Classificazione delle politiche:
\begin{itemize}
    \item \textbf{discretional access control (DAC)}: il creatore di un oggetto controlla i diritti di accesso per quell'oggetto (unix). La definizione delle politiche è
    decentralizzata.
    \item \textbf{mandatory access control (MAC)}: i diritti di accesso vengono definiti in modo centralizzato. Ad esempio in installazioni di alta sicurezza
    \item \textbf{role based access control (RBAC)}: ad un ruolo sono assegnati specifici diritti di accesso sulle risorse. Sli utenti possono appartenere a diversi
    ruoli. I diritti attribuiti ad ogni ruolo vengono assegnati in modo centralizzato
\end{itemize}

\vspace{3mm}
\textbf{Principio del privilegio minimo}: ad ogni soggetto sono garantiti i diritti d'accesso solo agli oggetti strettamente necessari per la sua esecuzione
(POLA: principle of least authority). il POLA è una caratteristicha desiderabile in ogni sistema di controllo.
\vspace{3mm}

\textbf{Meccanismi:}

I \textbf{meccanismi di protezione} sono gli strumenti necessari a mettere in atto una determinata politica.
Principi di realizzazione:
\begin{itemize}
    \item \textbf{Flessibilità del sistema di protezione}: i meccanismi devono essere sufficientemente generali per consentire l'applicazione di diverse politiche 
    di protezione
    \item \textbf{Separazione tra meccanismi e politiche}: la politicha definische "cosa va fatto" ed il meccanismo "come va fatto". Ovviamente è desiderata la
    massima indipendenza tra le due componenti.
\end{itemize}

\subsection{Dominio di protezione}
Un dominio definisce un insiem edi coppie, ognuna contenente l'identificatore di un oggetto e l'insieme delle operazioni che il soggetto associato al
dominio può eseguire su ciascun oggetto

\vspace{3mm}
$D(S)$ = $\{$$<$o, diritti$>$ $|$ o è un oggetto, diritti è un insieme di operazioni$\}$
\vspace{3mm}

\textbf{Modello di Grahmm-Denning}

Questo modello forsnisce una serie di comandi che garantiscono la modifica controllata dello stato di protezione:
\begin{itemize}
    \item create object
    \item delete object
    \item create subject
    \item delete subject
    \item read access right
    \item grant access right
    \item delete access right
    \item tranfer access right
\end{itemize}

\vspace{3mm}
\subsubsection{Diritti}

\textbf{Diritto Owner}:
\vspace{3mm}

Il diritto owner permette l'assegnazioen di qualunque diritto di accesso su un oggetto X ad un qualunque soggetto Sj da parte di un soggetto Si. L'operazione è consentita solo
se il diritto owner appartiene a A[Si, X]

\vspace{3mm}
\textbf{Diritto Control}:
\vspace{3mm}

Eliminazione di un diritto di accesso per un oggetto X nel dominio di Sj da parte di Si. L'operazione è consentita solo se il diritto control appartiene a A[Si, Sj], oppure owner
appartiene a A[Si, X].

\vspace{3mm}
\textbf{Cambio di dominio: switch}
\vspace{3mm}

Il cambio di dominio permette che un processo che esegue nel dominio del soggetto si può commutare al dominio di un altro soggetto Sj.
L'operazione è consentita solo se il diritto switch appartiene a A[Si, Sj].

\subsection{Realizzazione della matrice delgi accessi}
La matrice degli accessi è una notazione astratta che rappresenta lo stato di protezione. Nella rappresentazione concreta è necessario considerare: la dimensione della matrice e matrice 
sparsa.

La rappresentazione concreta della matrice degli accessi deve essere ottimizzata sia riguardo all'occupazione di memoria sia rispetto all'efficienza nell'accesso e nella gestione della
informazioni di protezione.
Ci sono principalmente di approcci:
\begin{itemize}
    \item \textbf{Access Control List (ACL)}: rappresentazione per colonne, per ogni oggetto è associata una lista che contiene tutti i soggetti che possono accedere all'oggetto, con i relativi diritti
    d'accesso per l'oggetto
    \item \textbf{Capability List}: rappresentazione per righe, ad ognin soggetto è associata una lista che contiene gli oggetti accessibili dal soggetto ed i relativi diritti d'accesso.
\end{itemize}

\subsubsection{Access Control List}
La lista degli accessi per ogni oggetto è rappresentata dall'insieme delle coppie: \textbf{$<$soggetto, insieme dei diritti$>$}
limitatamente ai soggetti con un insieme non vuoto di diritti per l'oggetto.

Quando deve essere eseguita un'operazione M su un oggetto Oj, da parte di Si, si cerca nella lista degli accessi \textbf{$<$Si, Rk$>$, con M appartenente a Rk}.

La ricerca può essere fatta preventivamente in una lista di default contenete i diritti di accesso applicabili a tutti gli oggetti. 
Se in entrambi i casi la risposta è negativa, l'accesso è negato.

\vspace{3mm}
\textbf{Utenti e Gruppi}
\vspace{3mm}

Generalmente ogni soggetto rappresenta un singolo utente. Molti sistemi hanno il concetto di \textbf{gruppo di utenti}. I gruppi hanno un nome e possono essere inclusi nella ACL.

In questo caso l'entry in ACL ha la forma:
\textbf{UID-1, GID-1 : $<$insieme di diritti$>$}

\textbf{UID-2, GID-2 : $<$insieme di diritti$>$}

Dove UID è lo user identifier e GID è il group identifier.

\vspace{3mm}
In certi casi il gruppo identifica un ruolo: uno stesso utente può appartenere a gruppi diversi e quindi  con diritti diversi. In questo caso, quando un utente accede, specifica il
gruppo di appartenenza.

\subsubsection{Capability List}
La lista delle capability, per ogni soggetto, è la lista di elementi ognuno dei quali:
\begin{itemize}
    \item è associato a un oggetto a cui il soggetto può accedere
    \item contiene i diritti di accessi consentiti su tale oggetto
\end{itemize}

\vspace{3mm}
Ogni elemento della lista prende il nome di \textbf{capability}. Il quale di compone di un identificatore (o un indirizzo) che indica l'oggetto e la rappresentazione dei vari diritti d'accesso.
Quando S intende eseguire un'operazione M su un oggetto Oj: il meccanismo di protezione controlla se nella lisra delle capability associata a S ne esiste una relativa ad Oj che abbia
tra i suoi diritti M.

\vspace{3mm}
Ovviamente le Capability List devono essere protette da manomissioni, ed è possibile in diversi modi:
\begin{itemize}
    \item la capability list viene gestita solamente da s.o.; l'utente fa riferimento ad un puntatore (capability) che identifica la sua posizione nella lista appartenete allo spazio del kerner
    \item Architettura etichettata: a livello HW, ogni singola parola ha bit extra, che esprimono la protezione su quella cella di memoria. Ad esempio, se è una capability, deve essere
    protetta da scritture non autorizzate.
\end{itemize}

\vspace{3mm}
I bit tag non sono utilizzari dall'aritmetica, dai confronti e da altre istruzioni normali e può essere modificato solo da programmi che agiscono in modo kernel.

\vspace{3mm}
\subsubsection{Revoca dei diritti di accesso}

In un sistema di protezione dinamica può essere necessario revocare i diritti d'accesso per un oggetto. La revoca può essere di tre tipi:
\begin{itemize}
    \item \textbf{generale o selettiva}: cioè valere per tutti gli utenti che hanno quel diritto di accesso o solo per un gruppo
    \item \textbf{parziale o totale}: cipè riguardare un sottoinsieme di diritti per l'oggetto, o tutti
    \item \textbf{temporanea o permanente}: cioè il diritto di accesso non sarà più disponibile, oppure potrà essere successivamente riottenuto
\end{itemize}

\vspace{3mm}
\textbf{Revoca del diritto per un oggetto con ACL}:

Si fa riferimento alla ACL associata all'oggetto e si cancellano i diritti di accesso che si vogliono revocare

\vspace{3mm}
\textbf{Revoca del diritto per un oggetto con Capability List}:

Più complicato rispetto ad ACL. È necessario verificare per ogni dominio se contiene la capability con riferimento all'oggetto considerato.

\subsection{Protezione e Sicurezza}

La protezione riguarda solamente il controllo degli accessi alle risorse interne al sistema. Invece la sicurezza si occupa di controllare gli accessi al sistema stesso.

In alcuni casi la sola protezione può non essere efficace, nel caso in cui, ad esempio, un utente autorizzato riesce a far eseguire programmi che agiscono sulle
risorse del sistema.

\subsubsection{Sicurezza Multilivello}

La maggior parte dei sistemi operativi permette ai singoli utenti di determinare chi possa leggere e scrivere i loro file ed oggetti. Invece in acluni ambienti
è richiesto e necessario un più stretto controllo sulle regole di accesso alle risorse (ambiente militare, ospedaliero, ecc). Vengono quindi stabilite delle regole
\textbf{generali} su "chi può accedere e a che cosa", che possono essere modificate solo da un'entità centrale autorizzata.

Quando è necessario un controllo obbligatorio degli accessi al sistema, l'organizzazione a cui il sistema appartiene definisce le politiche \textbf{MAC} che
stabiliscono le \textbf{regole generali} tramite l'adozione di un modello di sicurezza.

\vspace{3mm}
I modelli di sicurezza più utilizzati sono:
\begin{itemize}
    \item modello \textbf{Bell-La Padula}
    \item modello \textbf{Biba}
\end{itemize}

Entrambi sono modelli multilivello.

\vspace{3mm}
In un modello di sicurezza multilivello i \textbf{soggetti} (utenti) e gli \textbf{oggetti} (risorse, file, ecc) sono \textbf{classificati} in \textbf{livelli} (classi
di accesso):
\begin{itemize}
    \item Livelli per i soggetti (\textbf{clearance levels})
    \item Livelli per gli oggetti (\textbf{sensivity levels})
\end{itemize}

\vspace{3mm}
Il modello inoltre fissa le \textbf{regole di sicurezza}, le quali controllano il flusso delle informazioni tra i livelli.

\vspace{3mm}
\textbf{Modello Bell-La Padula}
\vspace{3mm}

Modello progettato per realizzare la sicurezza in organizzazioni militari, garantendo la \textbf{confidenzialità} delle informazioni.

Associa a un sistema di protezione (matrice degli accesso) due regole di sicurezza MAC, che stabiliscono la direzione di propagazione delle informazioni nel sistema.

\vspace{3mm}
Quattro livelli di sensibilità degli oggetti:
\begin{itemize}
    \item Non classificato
    \item Confidenziale
    \item Segreto
    \item Top secret
\end{itemize}

\vspace{3mm}
Quattro livelli di autorizzazione (clearance) per i soggetti:

Le persone sono assegnate ai livelli a seconda del ruolo nell'organizzazione.

\vspace{3mm}
\textbf{Regole di Sicurezza}:
\begin{itemize}
    \item \textbf{Proprietà di semplice sicurezza}: un processo in esecuzione al livello di sicurezza k può leggere solo oggetti al suo livello o a livelli inferiori
    \item \textbf{Proprietà *}: un processo in esecuzione al livello di sicurezza k può scrivere solamente oggetti al suo livello o a quelli superiori
\end{itemize}

Quindi i processi possono leggere verso il basso e scrivere verso l'alto, ma non il contrario. (flusso delle informazioni dal basso verso l'alto).

\vspace{3mm}
Generalmente a queste regole si aggiungono le regole di protezioen speficicate dalla matrice degli accessi.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.70\columnwidth]{imgs/bell-padula.PNG}
\end{figure}

\vspace{3mm}
Il modello Bell-La Padula è stato concepito per mantenere i segreti, non per garantire l'integrità dei dati. E\' possibile infatti sovrascrivere l'informazione
appartenente ad un livello superiore.

\vspace{3mm}
Esempio cavallo di troia

\vspace{3mm}
\textbf{Modello Biba}
\vspace{3mm}

Se il modello Bell-La Padula è stato concepito per mantenere i segreti e non per garantire l'integrità dei dati, il Modello Biba ha come obiettivo principale proprio
l'integrità dei dati.

\vspace{3mm}
\begin{itemize}
    \item \textbf{Proprietà di semplice sicurezza:} un processo in esecuzione al livello di sicurezza k può scrivere solamente oggetti al suo livello o a quelli
    inferiori (nessuna scrittua verso l'alto)
    \item \textbf{Proprietò di integrità *}: un processo in esecuzione al livello k può leggere solo oggetti al suo livello o quelli superiori (nessuna lettura
    verso il basso)
\end{itemize}

Ovviamente il modello Biba è in conflitto con il modello B-LP e quindi non possono essere utilizzati contemporaneamente.

\subsubsection{Architettura dei sistemi ad elevata sicurezza}

\textbf{Sistemi operativi sicuri, o fidati}: sistemi per i quali è possibile definire formalmente dei requisiti di sicurezza.

\vspace{3mm}
\textbf{Reference Monitor}: è un elemento di controllo realizzato dall'hardware e dal S.O. che regola l'accesso dei soggetti agli oggetti sulla base di paramentri
di sicurezza (es. modello Bell-La Padula)

\vspace{3mm}
\textbf{Trusted computing base}: il RM ha accesso ad una base di calcolo fidata (Trusted computing base, o TBC) che contiene:
\begin{itemize}
    \item Privilegi dei sicurezza (autorizzazioni di sicurezza) di ogni soggetto
    \item Attributi (classificazione rispetto alla sicurezza) di ciascun oggetto
\end{itemize}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.70\columnwidth]{imgs/elevata_sicurezza.PNG}
\end{figure}

\vspace{3mm}
\textbf{Sistemi fidati}
\vspace{3mm}

Il RM impone le regole di sicurezza (B-LP: no read-up, no write-down) ed ha le seguenti proprietà:
\begin{itemize}
    \item \textbf{Mediazione completa}: le regole di sicurezza vengono applicate ad ogni accesso e non solo, ad esempio, quando viene aperto un file
    \item \textbf{Isolamento}: il monitor dei riferimenti e la base di dati sono protetti rispetto a modifiche non autorizzate (es. kernel)
    \item \textbf{Verificabilità}: la correttezza del RM deve essere provata, cioè deve essere possibile dimostrare formalmente che il monitor impone le regole
    di sicurezza e fornisce mediazione completa ed isolamento
\end{itemize}

\vspace{3mm}
Il requisito di \textbf{mediazione completa} rende preferibile, per motivi di efficienza, che la soluzione debba essere almeno parziamente hardware.

\vspace{3mm}
Il requisito di \textbf{isolamento} impone che non sia possibile oer chi porta l'attacco, modificare la logica del RM o il contenuto del DB centrale della sicurezza.

\vspace{3mm}
Il requisito della \textbf{verificabilità} è difficile da soddisfare per un sistema general-purpose.

\newpage

\section{Programmazione Concorrente}




\newpage

\section{Modello a memoria comune}

Esistono 2 principali modelli di interazione tra i processi:
\begin{itemize}
    \item Modello a \textbf{memoria comune} (ambiente globale, shared memory)
    \item Modello a \textbf{scambio di messaggi} (ambiente locale, distributed memory)
\end{itemize}

Il modello a memoria comune rappresenta la più semplice astrazione del funzionamento di un sistema in multiprogrammazione costituito da uno o più processi che hanno accesso
ad una memoria comune.

Ogni appliczione viene strutturata come un insieme di componenti, suddiviso in due sottoinsieme disgiunti:
\begin{itemize}
    \item \textbf{Processi} (componenti attivi)
    \item \textbf{Risorse} (componenti passivi)
\end{itemize}

Le Risorse rappresentatno un qualunque oggettim fisico o logico, di cui un processo necessita per portare a termine il suo compito.
Le risorse vengono raggruppate in classi, dove una classe rappresenta l'insieme di tutte e sole le operazioni che un processo può eseguire per operare su risorse di quella classe,

Ovviamente ci deve essere la necessità di specificare quali processi ed in quali istanti possono accedere alla risorsa. Quindi il \textbf{meccanismo di controllo degli accessi}
si occupa di controllare che gli accessi dei processi alle risorse avvengano correttamente.

\subsection{Gestore delle Risorse}

Per ogni risorsa \textbf{R}, il suo gestore definisce, in ogni istante t, \textbf{l'insieme SR(t) dei processi che, in tale istante, hanno il diritto di operare su R}.

\vspace{5mm}

Classificazione delle risorse:
\begin{itemize}
    \item Risorsa R \textbf{dedicata}: se SR(t) ha una caardianlità sempre <= 1
    \item Risorsa R \textbf{condivisa}: in caso contrario
    \item Risorsa R \textbf{allocata staticamente}: se SR(t) è una costante, quindi se SR(t) = SR(t0) per ogni t
    \item Risorsa R \textbf{allocata dinamicamente}: se SR(t) è funzione del tempo
\end{itemize}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.50\columnwidth]{imgs/tipologie_allocazione.png}
\end{figure}

Per ogni risorsa \textbf{allocata staticamente}, l'insieme SR(t) è definito prima che il programma inizi la propria esecuzione; il gestore della risorsa è il programmatore che,
in base alle regole del linguaggio, stabilisce quale processo può vedere e quindi operare su R.


Per ogni risorsa \textbf{allocata dinamicamente}, il relativo gestore GR definisce l'insieme SR(t) in fase di esecuzione e quindi deve essere un componente della stessa applicazione,
nel quale l'allocazione viene decisa a run-time in base a politiche date.

\vspace{5mm}
Quindi i principali compiti del Gestore delle risorse sono:
\begin{itemize}
    \item mantenere \textbf{aggiornato} l'insieme SR(t) e cioè lo stato di allocazione della risorsa
    \item fornire i \textbf{meccanismi} che un processo può utilizzare per acquisire il diritto di operare sulla risorsa, entrando a far parte dell'insieme SR(t), e per rilasciare
    tale diritto quando non è più necessario
    \item implementare la \textbf{startegia} di allocazione della risorsa e cioè definire quando, a chi e per quanto tempo allocare la risorsa.
\end{itemize}

\vspace{5mm}
{\large \textbf{Accesso a Risorse}}
Consideriamo un processo P che deve operare, ad un certo istante, su una risorsa R di tipo T:

Se R è allocata \textbf{staticamente} a P (modalità A e B), il processo, se appartiene a SR, possiede diritto di operare su R in qualunque istante.
\vspace{3mm}
\begin{lstlisting}
R.op(...);
\end{lstlisting}

Se R è allocata \textbf{dinamicamente} a P (modalità C e D), è necessario prevedere un gestore GR, che implementa le funzioni di Richiesta e Rilascio della risorsa; quindi il
processo P deve seguire il seguente protocollo:

\vspace{3mm}
\begin{lstlisting}
GR.Richiesta(...);  // acquisizione della risorsa
R.op(...);          // esecuzione dell'operazione op su R
GR.Rilascio(...);   // rilascio della risorsa R
\end{lstlisting}

\vspace{3mm}
Se R è allocata come \textbf{risorsa condivisa}, (modalità B e D) è necessario assicurare che gli accessi avvengano in modo non divisibile: nel senso che òe funzioni di accesso alla
risorsa devono essere programmate come una \textbf{classe di sezioni critiche}, utilizzando meccanismi di sincronizzazione offerti dal linguaggio di programmazione e supportati
dalla macchina concorrente.

\vspace{3mm}
Se R è allocata come \textbf{risorsa dedicata}, (modalità A e C), essendo P l'unico processo che accede alla risorsa, non è necessario prevedere alcuna forma di sincronizzazione.

\vspace{5mm}
{\large \textbf{Regione critica condizionale [Hoare, Brinch-hansen]}}
Formalismo che permette di esprimere la specifica di qualunque vincolo di sincronizzazione. Data una risorsa R condivisa:

\begin{lstlisting}
region R << Sa; when(C) Sb; >>
\end{lstlisting}

\begin{itemize}
    \item tra doppie parentesi angolai il \textbf{corpo} della region che rappresenta una operazione da eseguire su una risorsa condivisa R e quindi costituisce una sezione critica
    che deve essere eseguita in \textbf{mutua esclusione} con le altre operazioni definite su R
    \item il corpo della region è costituito da due istruzioni da eseguire in sequenza: l'istruzione \textbf{Sa} e successivamente l'istruzione \textbf{Sb}
    \item in particolare, una volta terminata l'esecizione di Sa viene valutata la condizione \textbf{C}:
    \begin{itemize}
        \item se C è \textbf{vera} l'esecuzione continua con Sb
        \item se C + \textbf{false} il processo che ha invocato l'operazione attende che la condizione C diventi vera. Non appena C sarà vera l'esecuzione della region potrà riprendere
        ed eseguire Sb
    \end{itemize}
\end{itemize}

Esistono però dei casi particolari di regioni critiche:
\begin{itemize}
    \item \textbf{region R $<<$ S; $>>$}: specifica della sola mutua esclusione, senza ulteriori vincoli
    \item \textbf{region R $<<$ when(C) $>>$}: specifica di un semplice vincolo di sincronizzazione, nel quale il processo deve attendere che C sia verificata prima di proseguire
    \item \textbf{region R $<<$ when(C) S; $>>$}: specifica il caso dìin cui la condizione C di sincronizzazione caratterizza lo stato in cui la risorsa R deve trovarsi per poter
    eseguire l'operazione S (C quindi è una precondizione di S)
\end{itemize}

\subsection{Mutua Esclusione}

Il probelma della mutua esclusione nasce quando più di un processo alla volta può e deve accedere a variabili comuni. Quindi è di fondamentale importanza che le operazioni con le quali
i processi accedono alle variabili comuni non si sovrappongano nel tempo.

\vspace{3mm}
Con sezione critica s'intende la sequenza di istruzioni con le quali un processo accede e modifica un insieme di variabili comuni. Ad un insieme di variabili comuni possono
essere associate una sola sezione critica (usata da tutti i processi) oppure più sezioni critiche (classe di sezioni critiche).

La regola della mutua esclusione stabilisce che:
\begin{center}
    \textbf{Sezioni critiche appartenenti alla atessa classe devono escludersi mutuamente nel tempo.}
    \vspace{3mm}

    oppure

    \vspace{3mm}
    \textbf{Ad ogni istante può essere "in esecuzione" al più una sezione critica di ogni classe.}
\end{center}

\vspace{3mm}
Per specificare una sezione critica \textbf{S} che opera su una risorsa condivisa R:

\begin{lstlisting}
    <prologo>
        S;
    <epilogo>
\end{lstlisting}

Attraverso il \textbf{prologo} si ottiene l'autorizzazione ad eseguire la sezione critica, quindi R viene acquisita in modo esclusivo. Invece attraverso l'\textbf{epilogo}
la risorsa R viene liberata.

\vspace{5mm}
Le principali soluzioni possibili alla mutua esclusine sono:
\begin{itemize}
    \item \textbf{Algoritmiche:} (es. Algoritmi di Dekker, ecc.) la soluzione non necessita di meccanismi di sincronizzazione (es. semafori, lock, ecc.), ma sfrutta
    solo la possibilità di condivisione di variabili; l'attesa di un processo che trova la variabile condivisa già occupata viene modellata attraverso cicli di attesa attiva
    \item \textbf{Hardware-based:} ad esempio disabilitazione delle interruzioni, lock/unlock. Quindi il supporto è fornito direttamente dall'architettura HW.
    \item \textbf{Strumenti software di sincronizzazione realizzati dal nucleo della macchina concorrente:} prologo ed epilogo sfruttano strumenti di sincronizzazione
    che consentono l'effettiva sospensione dei processi in attesa ed eseguire sezioni critiche.
\end{itemize}

\subsection{Strumenti linguistici per la programmazione di interazioni}
\subsubsection{Il Semaforo}

Il semaforo è uno strumento linguistico di basso livello che consente di risolvere qualunque problema di sincronizzazione nel modello a memoria comune.

E\' realizzato dal nucleo della macchina concorrente. L'eventuale attesa nella esecuzione può essere realizzata utilizzando i meccanismi di gestione dei thread offerti
dal nucleo. Inoltre viene utilizzato per realizzaer strumenti di sincronizzazione di puù alto livello ad esempio le \textit{condition}.

\vspace{3mm}
\textbf{Definizione:} un semaforo è una \textbf{variabile intera non negativa}, alla quale è possibile accedere solo \textbf{tramite le due operazioni P e V}.
\vspace{3mm}

Definizione di un oggetto di tipo \textbf{semaphore}:
\begin{lstlisting}
    semaphore s = i;    // dove i (i >= 0) è il valore iniziale
\end{lstlisting}

Al tipo semaphore sono associati:
\begin{center}
    Insieme di valori = $\{X | X \in N\}$
    \vspace{3mm}

    Insieme delle operazioni = $\{P, V\}$
\end{center}

\vspace{5mm}
\textbf{Operazioni sul semaforo}
\vspace{3mm}

Un oggetto di tipo semaphore è condivisibile da due o più threads, che operano su di esso attraverso le operazioni \textbf{P} e \textbf{V}.

\begin{lstlisting}
    void P(semaphore s):
        region s << when(val_s > 0) val_s--; >>

    void V(semaphore s):
        region s << val_s++; >>

    // dove val_s rappresenta il valore del semaforo
\end{lstlisting}

Essendo \textbf{s} l'oggetto condiviso, le due operazioni P e V vengono definite come \textbf{sezioni critiche} da eseguire in mutua esclusione e in forma atomica.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.50\columnwidth]{imgs/operazioni_semaforo.PNG}
\end{figure}

Quindi il semaforo viene utilizzato come strumento di sincronizzazione tra processi concorrenti:
\begin{itemize}
    \item \textbf{attesa}: P(s), val-s == 0
    \item \textbf{risveglio}: V(s), se vi è almeno un processo sospeso
\end{itemize}

\vspace{5mm}
\textbf{Proprietà del Semaforo}
\vspace{3mm}
Dato un semaforo S, siano:
\begin{itemize}
    \item \textbf{$val_s$}: valore dell'intero non negativo associato al semaforo;
    \item \textbf{$I_s$}: valore intero \>= 0 con cui il semaforo s viene inizializzato;
    \item \textbf{$nv_s$}: numero di volte che l'operazione V(s) è stata eseguita;
    \item \textbf{$np_s$}: numero di volte che l'operazione P(s) è stata completata.
\end{itemize}

\vspace{3mm}
Ad ogni istante possiamo esprimere il valore del semafor come:
\begin{center}
    $val_s = I_s + nv_s - np_s$
\end{center}

da cui ($val_s >= 0$):

\begin{center}
    \textbf{Relazione di Invarianza}

    \textbf{$np_s <= I_s + nv_s$}
\end{center}

La relazione di invarianza è sempre soddisfatta, per ogni semaforo, qualunque sia il suo valore e comunque sia strutturato il programma concorrente che lo usa.

\vspace{5mm}
Il semaforo è quindi uno strumento generale che consente la risoluzione di qualunque problema di sincronizzazione.

Esistono molti casi d'uso del meccanismo semaforico:
\begin{itemize}
    \item semafori di mutua esclusione
    \item semafori evento
    \item semafori binari composti
    \item semafori condizione
    \item semafori risorsa
    \item semafori privati
\end{itemize}

\vspace{5mm}
\textbf{Semaforo di mutua esclusione}

\vspace{3mm}
Il semaforo di mutua esclusione viene inizializzato ad 1. Principalmente viene utilizzato per realizzare le sezioni critiche di una stessa classe, secondo il protocollo:

\begin{lstlisting}
    class tipo_risorsa {
        <struttura dati di ogni istanza della classe>;

        semaphore mutex = 1;

        public void op1() {
            P(mutex);   // prologo
            <sezione critica: corpo della funzione op1>;
            V(mutex);   // epilogo
        }

        public void opN() {
            P(mutex);   // prologo
            <sezioen critica: corpo della funzione opN>;
            V(mutex);   // epilogo
        }
    }

    tipo_risorsa ris;
    ris.opi();
\end{lstlisting}

(il semaforo di mutua esclusione può assumere solo i valori 0 e 1)

\vspace{3mm}
In alcuni casi è consentito a più processi di eseguire contemporaneamente la stessa operazione su una risorsa, ma non operazioni diverse.

Quindi una soluzione protrebbe essere:
\begin{itemize}
    \item definisco un semaforo mutex per la mutua esclusione tra operazioni
    \item prologo ed epilogo di $op_i$ sono sezioni critiche quindi introduco un ulteriore semaforo di mutua esclusione $m_i$
\end{itemize}

Un esempio potrebbe essere il \textbf{problema dei lettori/scrittori}.

Sia data una risorsa condivisa F (ad esmepio un file) che può essere acceduta dai thread concorrenti in due modi:
\begin{itemize}
    \item \textbf{lettura};
    \item \textbf{scrittura}
\end{itemize}

\vspace{3mm}
Una possibile soluzione di sincronizzazione potrebbe essere:
\begin{itemize}
    \item la lettura è consentita a più thread contemporaneamente;
    \item la scrtittura è consentita ad un thread alla volta;
    \item lettura e scrittura su F non possono avvenire contemporaneamente
\end{itemize}

\begin{lstlisting}
    semaphore mutex = 1;
    semaphore ml = 1;
    int contl = 0;

    public void lettura(...) {
        P(ml);
        contl++;

        if(contl == 1) {
            P(mutex);
        }

        V(ml);
        <lettura del file>;
        P(ml);
        contl--;

        if(contl == 0) {
            V(mutex);
        }

        v(ml);
    }

    public void scrittura(...) {
        P(mutex);
        <scrittura del file>;
        V(mutex);
    }
\end{lstlisting}

\vspace{5mm}
\textbf{Semaforo evento}

\vspace{3mm}
Un semaforo evento è un semaforo binario utilizzato per imporre un \textbf{vincolo di precedenza} tra le operazioni dei processi. 
(ad es. $op_a$ deve essere eseguita da P1 solo dopo che P2 ha eseguito $op_b$).

\vspace{3mm}
Introduciamo quindi un semaforo \textbf{sem} inizializzato a \textbf{zero}:
\begin{itemize}
    \item prima di eseguire $op_a$, P1 esegue P(sem)
    \item dopo aver eseguito $op_b$, P2 esegue V(sem)
\end{itemize}

{
    problema del rendez-vous slide 48
}

\vspace{5mm}
\textbf{Semafori binari composti}

\vspace{3mm}
Un insieme di semafori usato in modo tale che:
\begin{itemize}
    \item uno solo di essi sia inizializzato a 1 e tutti gli altri a 0
    \item ogni processo che usa questi semafori esegue sempre sequenze che iniziano con la P su uno di questi e termina con la V su un altro.
\end{itemize}

Due processi P1 e P2 si scambiano dati di tipo T utilizzando una memoria condivisa (buffer).

Quindi devono esserci dei vincoli di sincronizzazione:
\begin{itemize}
    \item accessi al buffer mutuamente esclusivi
    \item P2 può prelevare un dato solo dopo che P1 lo abbia inserito
    \item P1, prima di inserire un dato, deve attendere che P2 abbia estratto il precedente
\end{itemize}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.60\columnwidth]{imgs/vincoli_precendenza.PNG}
\end{figure}

\vspace{3mm}
Utilizziamo quindi due semafori:
\begin{itemize}
    \item \textbf{vu}, per realizzare l'attesa di P1, in caso di buffer pieno
    \item \textbf{pn}, per realizzare l'attesa di P2, in caso di buffer vuoto
\end{itemize}

\vspace{3mm}
Buffer inizialmente vuoto, vu = 1, pn = 0
\vspace{3mm}

\noindent\begin{minipage}{.45\columnwidth}
    \begin{lstlisting}
        void invio(T dato) {
            P(vu);
            inserisci(dato);
            V(pn);
        }
    \end{lstlisting}
\end{minipage}\hfill
\begin{minipage}{.45\columnwidth}
    \begin{lstlisting}
        T ricezione() {
            T dato;
            P(pn);
            dato = estrai();
            V(vu);
            return dato;
        }
    \end{lstlisting}
\end{minipage}

\vspace{5mm}
\textbf{Semaforo condizione}

\vspace{3mm}
In alcuni casi l'esecuzione di un'istruzione S1 su una risorsa R è subordinata al verificarsi di una condizione C:

\begin{lstlisting}
    void op1(): region R << when(C) S1; >>
\end{lstlisting}

\vspace{3mm}
Il processo deve sospendersi se la condizione non è verificata e deve sucire dalla regione per consentire ad altri processi di eseguire altre operazioni su R
per rendere vera la condzione C.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.70\columnwidth]{imgs/schema_condizione.PNG}
\end{figure}

\begin{itemize}
    \item Lo schema (a) presuppone una forma di attesa attiva da parte del processo che non trova soddisfatta la condizione
    \item Nello schema (b) si realizza la region sospendendo il processo sul semaforo sem da associare alla condizione.
    \begin{itemize}
        \item è necessaria un'altra operazione op2 che, chiamata da un'altro processo, modifichi lo stato interno di R in modo che C diventi vera
        \item nell'ambito di op2 viene eseguita la V(sem) per risvegliare il processo
    \end{itemize}
\end{itemize}

\vspace{3mm}
Schema con \textbf{attesa circolare}

\begin{lstlisting}
semaphore mutex = 1;
semaphore sem = 0;
int csem = 0;
\end{lstlisting}

\noindent\begin{minipage}{.45\columnwidth}
    \begin{lstlisting}
public void op1() {
    P(mutex);
    while(!C) {
        csem++;
        V(mutex);
        P(sem);
        P(mutex);
    }
    S1;
    V(mutex);
}
    \end{lstlisting}
\end{minipage}\hfill
\begin{minipage}{.45\columnwidth}
    \begin{lstlisting}
public void op2() {
    P(mutex);
    S2;
    if(csem > 0) {
        csem--;
        V(sem);
    }
    V(mutex);
}
    \end{lstlisting}
\end{minipage}

\vspace{3mm}
Schema con \textbf{passaggio di testimone}:

\begin{lstlisting}
semaphore mutex = 1;
semaphore sem = 0;
int csem = 0;
\end{lstlisting}

\noindent\begin{minipage}{.45\columnwidth}
    \begin{lstlisting}
public void op1() {
    P(mutex);
    if(!C) {
        csem++;
        V(mutex);
        P(sem);
        csem--;
    }
    S1;
    V(mutex);
}
    \end{lstlisting}
\end{minipage}\hfill
\begin{minipage}{.45\columnwidth}
    \begin{lstlisting}
public void op2() {
    P(mutex);
    S2;
    if(C && csem > 0) {
        V(sem);
    } else {
        V(mutex);
    }
}
    \end{lstlisting}
\end{minipage}

\vspace{3mm}
Questo secondo schema è più efficientre del primo ma ha comunque delle limitazioni. Permette di risvegliare un solo processo alla volta poichè ad uno solo può passare
il diritto di operare in mutua esclusione. Inoltre la condizione C (precondizione di S1) deve essere verificabile anche all'interno di op2. Ciò significa che
non deve contenere variabili locali o parametri della funzione op1.

\vspace{5mm}
\textbf{Semaforo condizione}

\vspace{3mm}
I semafori risorsa sono semafori generali, quindi possono assumere qualunque valore >= 0. Vengono generalmente impiegati per realizzare l'allocazione di risorse
equivalenti, nel quale il valore del semaforo rappresenta il numero di risorse libere.

\vspace{3mm}
\begin{lstlisting}
class tipo_gestore {
    semaphore mutex = 1;    // semaforo di mutua esclusione
    semaphore n_ris = N;    // semaforo risorsa
    boolean libera[N];      // indicatori di risorsa libera

    public tipo_gestore() {
        for(int i = 0; i < N; i++) {
            libera[i] = true;   // inizializzazione
        }
    }

    public int richiesta() {
        int i = 0;
        P(n_ris);
        P(mutex);
        while(libera[i] == false) {
            i++;
        }
        libera[i] = false;
        V(mutex);
        return i;
    }

    public ovid rilascio(int r) {
        P(mutex);
        libera[r] = true;
        V(mutex);
        V(n_ris);
    }
}
\end{lstlisting}

\vspace{3mm}
Leggere esempi sulle condizioni di sincronizzazione.

\vspace{5mm}
\textbf{Semaforo privato}

\vspace{3mm}
Un semaforo S si deive privato per un processo quando solo tale processo può eseguire la primitiva P sul semaforo S. La primitiva V sul semaforo può essere invece eseguita
da qualunque processo. Generalmente un semaforo privato viene inizalizzato con il valore zero.

\vspace{3mm}
I semafori privati vengono utilizzati per realizzare particolari politiche di allocazione di risorse:
\begin{itemize}
    \item il processo che acquisisce la risorsa può eventualmente sospendersi sul suo semaforo privato (se la condizione di sincronizzazione non è rispettata)
    \item chi rilascia la risorsa, risveglierà uno tra i processi sospesi, in base alla politica scelta, mediante una V sul semaforo privato del processo scelto.
\end{itemize}

\vspace{3mm}
Allocazione di risorse, \textbf{primo schema}:

\begin{lstlisting}
class tipo_gestore_risorsa {
    <struttura dati del gestore>;
    semaphore mutex = 1;
    semaphore priv[n] = {0, 0, ..., 0}; // semafori privati

    public void acquisizione(int i) {
        P(mmutex);
        if(<condizione di sincronizzazione>) {
            <allocazione della risorsa>;
            V(priv[i]);
        } else {
            <registra la sospensione del processo>;
        }
        V(mutex);
        P(priv(i));
    }

    public void rilascio() {
        int i;
        P(mutex);
        <rilascio della risorsa>;
        if(<esiste almeno un processo sospeso per il quale la condizione risulta true>) {
            <scelta fra i processi sospesi quello destinato alla riattivazione (Pi)>;
            <allocazione della risorsa a Pi>;
            <registrare che Pi non e piu sospeso>;
            V(priv[i]);
        }
        V(mutex);
    }
}
\end{lstlisting}

\vspace{3mm}
Proprietà del primo schema:
\begin{itemize}
    \item la sospensione del processo, nel caso in cui la condizione di sincronizzazione non sia soddisfatta, non può avvenire entro la sezione critica in quanto 
    ciò impedirebbe ad un processo che rilascia la risorsa di accedere a sua volta alla sezione critica e di riattivare il processo sospeso. E quindi la sospensione
    avviene fuori dalla sezione critica.
    \item la specifica del particolare algoritmo di assegnazione della risorsa non è opportuno che sia realizzata nella primitiva V.
    \item questo schema può presentare i seguanti problemi:
    \begin{itemize}
        \item l'operazione P sul semaforo privato viene sempre eseguita anche quando il processo richiedente non deve essere bloccato
        \item il codice relativo all'assegnazione della risorsa viene duplicato nelle procedure acquisizione e rilascio
    \end{itemize}
\end{itemize}

\vspace{3mm}
Allocazione di risorse, \textbf{secondo schema} (supera i limiti del primo):

\begin{lstlisting}
class tipo_gestore_risorsa {
    <struttura dati del gestore>;
    semaphore mutex = 1;
    semaphore priv[n] = {0, 0, ..., 0};

    public void acquisizione(int i) {
        P(mutex);
        if(! <condizione di sincronizzazione>) {
            <registrare la sospensione del processo>;
            V(mutex);
            P(priv[i]);
            <resitrare che il processo non e piu sospeso>;
        }
        <allocazione della risorsa>;
        V(mutex);
    }

    public void rilascio() {
        int i;
        P(mutex);
        <rilascio della risorsa>;
        if(<esiste almeno un processo sospeso per il quale la condizione risulta true>) {
            <scelta del processo Pi da riattivare>;
            V(priv[i]);
        } else {
            V(mutex);
        }
    }
}
\end{lstlisting}

\vspace{3mm}
Rispetto al primo schema, in questa soluzione risulta più complesso realizzare la riattivazione di più processi per i quali risulti vera contemporaneamente la
condizione di sincronizzazione. Infatti il processo che rilascia la risorsa attiva al più un processo sospeso, il quale dovrà a sua volta provvedere alla riattivazione
di eventuali altri processi.

\newpage

\section{Realizzazione del nucleo}

Si chiama \textbf{nucleo} (o kernel) il modulo (o insieme di funzioni) realizzato in software, hardware o firmware che supporta il concetto di processo e realizza
gli strumenti necessari per la gestione dei processi.

\vspace{3mm}
Il nucleo costituisce il livello più interno di un qualunque sistema basato su processi, ad esempio:
\begin{itemize}
    \item il livello più elementare di un sistema operativo multiprogrammato
    \item il supporto a tempo di esecuzione di un linguaggio per la programmazione concorrente
\end{itemize}

Il nucleo è il solo modulo che è consio dell'esistenza delle interruzioni. I processi che colloquiano con i dispositivi utilizzano opportune primitive del
nucleo che provvedono a sospenderli in attesa del completamento dell'azione richiesta. Non appena l'azione viene completata, il relativo segnale di interruzione
iviato dal dispositivo alla CPU viene catturato dal nucleo che provvede a risvegliare il processo sospeso.

La gestione delle interruzioni è quindi invisibile ai processi ed ha come unico effetto rilevabile di rallentare la loro esecuzione sulle rispettive macchine virtuali.

\subsection{Caratteristiche fondamentali del nucleo}

\textbf{Efficienza}: condiziona l'intera struttura a processi. Infatti esistono dei sistemi in cui alcune o tutte le operazioni del nucleo sono realizzate in hardware
o attraverso microprogrammi.

\vspace{3mm}
\textbf{Dimensioni}: la semplicità delle funzioni richieste al nucleo fa si che la sua dimensinoe risulti estremamente limitata.

\vspace{3mm}
\textbf{Separazioen tra meccanismi e politiche}: il nucleo deve contenere solo meccanismi consentendo così, a livello di processi, di utilizzare tali meccanismi per la 
realizzazione di diverse politiche di gestione a seconda del tipo di applicazione.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.70\columnwidth]{imgs/processo.PNG}
\end{figure}

Le transizioni tra i due stati sono implementate dai meccanismi di sincronizzazione realizzati dal nucleo. \textbf{P} per sospensione e \textbf{V} per risveglio.

\vspace{3mm}
Stati di un processo in un sistema in cui il numero di processi supera il numero delle unità di elaborazione:
\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.70\columnwidth]{imgs/processi.PNG}
\end{figure}

Quando un processo perde il controllo del processore, il contenuto dei registri del processo viene salvato in un'area di memoria associata al processo, chiamata descrittore.

Ciò consente una maggiore flessibilità nella politica di assegnazione del processore ai processi, rispetto alla soluzione di salvare le informazioni nello stack.

\vspace{3mm}
Quindi la funzione fondamentale del nucleo di un sistema a processi è la gestione delle transizioni di stato dei processi. I principali compiti del nucleo sono:
\begin{itemize}
    \item \textbf{Gestire il salvataggio e il ripristino dei contesti dei processi}: quando un processo abbandona il controllo dell'unità di elaborazione fisica,
        tutte le informazioni contenute nei registri di tale unità devono essere trasferite nel descrittore. Allo stesso modo, quando un processo riprende l'esecuzione
        tutte le informazioni contenute nel suo descrittore devono essere trasferite nei registri di macchina
    \item \textbf{Scegliere a quale tra i processi pronti assegnare l'unità di elaborazione (scheduling della CPU)}: quando un processo abbandona il controllo
        dell'unità di elaborazione, il nucleo deve scegliere tra tutti i processi pronti quello da mettere in esecuzione. La scelta può essere o di tipo FIFO, oppure
        può utilizzare la priorità dei processi.
    \item \textbf{Gestire le interruzioni dei dispositivi esterni}: traducendole in attivazione di processi da bloccato a pronto.
    \item \textbf{Realizzare i meccanismi di sincronizzazione dei processi}: gestendo il passaggio dei processi dallo stato di esecuzioen allo stato di bloccato e da
        bloccato a pronto.
\end{itemize}

\subsection{Realizzazione del Nucleo: Architettura monoprocessore}

\subsubsection{Strutture Dati del Nucleo}

Il \textbf{Descrittore del processo} è la principale struttura dati del nucleo, e contiene le seguenti informazioni:
\begin{itemize}
    \item \textbf{Identificatore del processo}: nome che identifica univocamente il processo durante il suo tempo di vita
    \item \textbf{Stato del processo}
    \item \textbf{Modalità di Servizio}: contiene parametri di scheduling
    \begin{itemize}
        \item FIFO
        \item Priorità (fissa o variabile)
        \item Deadline (tempo massimo entro il quale la richiesta può essere soddisfatta)
        \item Quanto di temo (sistemi time sharing)
    \end{itemize}
    \item \textbf{Contesto del processo}: program counter, registro di stato, registri generali, indirizzo dell'area di memoria privata del processo.
    \item \textbf{Code di processo}: a seconda del loro stato i processi vengono inseriti in apposite code. Ogni descrittore contiene l'identificatore del processo successivo 
    nella stessa coda.
\end{itemize}

\begin{lstlisting}[caption={Realizzazione desctittore del processo},captionpos=b]
typedef struct {
    int indice_priorità;
    int delta_t;
} modalità_di_servizio;

typedef struct {
    int nome;
    modalità_di_servizio servizio;
    tipo_contesto contesto;
    tipo_stato stato;   // running, ready, waiting, ecc.
    int successivo;
} descrittore_processo;

descrittore_processo descrittori[num_max_proc];
\end{lstlisting}

\subsubsection{Coda dei processi pronti}

Esistono sempre una o più \textbf{code di processi pronti}. Non appena un processo viene riattivato tramite una \textbf{v} viene
inserito in fondo alla coda corrispondente alla sua priorità.

La coda dei processi pronti contiene sempre almeno un \textbf{dummy process} il quale viene messo in esecuzione solamente quando tutte
le altre code sono vuote e rimane in esecuzione fino a quando qualche altro processo diventa pronto. Inoltre il dummy process ha
la priorità più bassa ed è sempre nello stato di pronto.

\vspace{3mm}
\begin{lstlisting}[caption={Esempio di realizzazione coda dei processi pronti}]
typedef struct {
    int primo;
    int ultimo;
} descrittore_coda;

typedef descrittore_coda coda_a_livelli[Npriorita];

coda_a_livelli coda_processi_pronti;

// Inserimento => inserisce il processo di indice P nella coda C
void Inserimento(int P, descrittore_coda C) {

}

// Prelievo => estrae il primo processo dalla coda C e ristituisce il suo indice
int Prelievo(descrittore_coda C) {

}
\end{lstlisting}

\textbf{Coda dei descrittori liberi}:

Coda nella quale sono concatenati i descrittori disponibili per la creazione di nuovi processi
e nella quale sono reinseriti i descrittori dei processi terminati

\vspace{3mm}
\textbf{Processo in esecuzione}:

Il nucleo necessita di conoscere quale processo è in esecuzione. Questa informazione, rappresentata dall'indice del descrittore
del processo, viene contenuta in una particolare variabile del nucleo. Quando il nucleo viene inizializzato, viene creato un processo
e l'indice del processo viene assegnato a processo_in_esecuzione.

\subsection{Funzioni del Nucleo}

Le funzioni del nucleo realizzano le operazioni di \textbf{transizione di stato} per i singoli processi. Ogni transizione prevede il
prelievo da una coda del descrittore del processo coinvolto ed il suo inserimento in un'altra coda.

A tale scopo vengono utilizzate due procedure: \textbf{Inserimento} e \textbf{Prelievo} di un descrittore da una coda. Se la coda è vuota
si adotta l'ipotesi che il campo primo assuma il valore -1.

\vspace{3mm}
Le funzioni del nucleo vengono suddivise in due livelli:
\begin{itemize}
    \item \textbf{Livello Superiore}: il quale contiene tutte le funzioni direttamente utilizzabili dai processi sia esterni che interni,
    quali risposta ai segnali di interruzione e primitive per la creazione, eliminazione e sincronizzazione dei processi.
    \item \textbf{Livello Inferiore}: il quale realizza tutte le funzionalità di cambio di contesto, ad esmepio salvataggio del contesto
    del processo che si sospende nel suo descrittore, scelta di un nuovo processo da mettere in esecuzione tra quelli pronti e 
    ripristino del suo contesto.
\end{itemize}

\vspace{3mm}
L'ambiente di esecuzione delle funzioni del nucleo ha caratteristiche distinte dal quello dei processi. Infatti, per motivi di protezione,
le funzioni del nucleo sono le uniche che:
\begin{itemize}
    \item possono operare sulle strutture dati che rappresentano lo stato del sistema (descrittori, code di descrittori, semafori, ecc..)
    \item possono utilizzare istruzioni privilegiate (abilitazione e disabilitazione delle interruzioni, ecc)
\end{itemize}

Le funzioni del nucleo devono essere eseguite in modo mutuamente esclusivo. Inoltre i due ambienti di esecuzioen (nucleo e processi
utente) corrispondono a stati diversi di operazione dell'elaboratore (kernel e user). E il meccanismo di passaggio da uno all'altro
è basato sul meccanismo delle interruzioni.

In particolare:
\begin{itemize}
    \item Nel caso di funzioni chiamate da \textbf{processi esterni}, il passaggio all'ambiente del nucleo è ottenuto tramite il meccanismo di
    risposta al segnale di \textbf{interruzione}
    \item Nel caso di funzioni chiamate da \textbf{processi interni}, il passaggio è ottenuto tramite l'esecuzione di \textbf{system calls}
    \item In entrambi i casi, al completamento della funzione richiesta, il trasferimento all'ambiente user avviene tramite il
    meccanismo di \textbf{ritorno da interruzione (RTI)}
\end{itemize}

\subsubsection{Funzione di livello inferiore: Cambio di Contesto}

La funzione di cambio di contesto è costituita da 3 principali fasi:

\vspace{3mm}
\textbf{Salvataggio dello stato}:

Salvataggio del contesto del processo in esecuzione nel suo descrittore e inserimento del descrittore nella coda dei processi bloccati
o dei processi pronti.

\begin{lstlisting}
void Salvataggio_stato() {
    int j;
    j = processo_in_esecuzione;
    descrittori[j].contesto = <valori dei registri CPU>;
}
\end{lstlisting}

\vspace{3mm}
\textbf{Assegnazione della CPU}

Rimozione del processo a maggiore priorità dalla coda dei pronti e caricamento dell'identificatori di tale processo nel registro
processo in esecuzione.

\begin{lstlisting}
// scheduling: algoritmo con priorità
void Assegnazione_CPU() {
    int k = 0, j;
    while(coda_processi_pronti[k].primo == -1) {
        k++;
    }

    j = Prelievo(coda_processi_pronti[k]);
    processo_in_esecuzione = j;
}
\end{lstlisting}

\vspace{3mm}
\textbf{Ripristino dello stato}:

Caricamento del processo del nuovo processo nei registri di macchina.

\begin{lstlisting}
void Ripristino_stato() {
    int j;
    j = processo_in_esecuzione;
    <registro-temp> = descrittori[j].servizio.delta_t;
    <registro-CPU> = descrittori[j].contesto;
}
\end{lstlisting}

\vspace{3mm}
\textbf{Gestione del temporizzatore}:

Per consetire la modalità di servizio a divisione di tempo è necessario che il nucleo gestica un \textbf{dispositivo temporizzatore}
tramite un'apposita procedura che ad intervalli di tempo fussati, provveda a sospendere il processo in esecuzione ed assegnare l'unità
di elaborazione ad un altro processo.

\begin{lstlisting}
void Cambio_di_Contesto() {
    int j, k;
    Salvataggio_stato();
    j = processo_in_esecuzione;
    k = descrittori[j].servizio.priorità;
    Inserimento(j, coda_processi_pronti[k]);
    Assegnazione_CPU();
    Ripristino_stato();
}
\end{lstlisting}

\subsection{Realizzazione Semaforo (caso monoprocessore)}

Nel nucleo di un sistema monoprocessore il semaforo può essere implementato tramite:
\begin{itemize}
    \item una variabile intera che rappresenta il suo valore (>=0)
    \item un puntatore ad una lista di descrittori di processi in attesa sul semaforo (bloccati)
\end{itemize}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.60\columnwidth]{imgs/sem_kernel.png}
\end{figure}

\vspace{3mm}
Se non sono presenti semafori in coda, il puntatore alla lista contiene la costante \textbf{nil}.

La coda viene gestita con politica FIFO, e quindi i processi risultano ordinati secondo il loro tempo di arrivo nella coda associata
al semaforo.

Il descrittore di un processo viene inserito nella coda del semaforo come conseguenza di una primitiva p non passsante, e viene prelevato
per effetto di una v.

\vspace{3mm}
\begin{lstlisting}
// gestione dei processi basata su priorità => associamo al semaforo un insieme di code (una per priorità)

typedef struct {
    int contatore;
    coda_a_livelli coda;
} descr_semaforo;
\end{lstlisting}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.60\columnwidth]{imgs/op_p_ker.png}
\end{figure}

\begin{lstlisting}
// insieme di tutti i semafori
descr_semaforo semafori[num_max_sem];

//ogni semaforo è rappresentato dall'indice che lo individua nel vettore semafori
typedef int semaforo;

void P(semaforo s) {
    int j, k;
    if(semafori[s].contatore == 0) {
        Salvataggio_stato();
        j = processo_in_esecuzione;
        k = descrittori[j].servizio.priorita;
        Inserimento(j, semafori[s].coda[k]);
        Assegnazione_CPU();
        Ripristino_stato();
    } else {
        contatore--;
    }
}
\end{lstlisting}

\vspace{3mm}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.60\columnwidth]{imgs/op_v_ker.png}
\end{figure}

\begin{lstlisting}
void V(semaforo s) {
    int j, k, p, q; // j,k: processi; p,q: indici priorita
    q = 0;

    while(semafori[s].coda[q].primo == -1 && q < min_priorita) {
        q++;
    }

    if(semafori[s].coda[q].primo != -1) {
        k = Prelievo(semafori[s].coda[q]);
        j = processo_in_esecuzione;
        p = descrittori[j].servizio.priorita;
        if(p < q) {
            // il processo in esecuzione è prioritario
            Inserimento(k, coda_processi_pronti[q]);
        } else {
            // preemption
            Salvataggio_stato();
            Inserimento(j, coda_processi_pronti[p]);
            processo_in_esecuzione = k;
            Ripristino_stato();
        }
    } else {
        semafori[s].contatore++;
    }
}
\end{lstlisting}

\subsection{Passaggio da ambiente di nucleo all'ambiente processi e viceversa}

Il passaggio da ambiente di nucleo all'ambiente di processi e viceversa è basato sul meccanismo di \textbf{interruzioni}
(interne o asincrone, interne o sincrone). In entrambi i casi, al completamento della funzione richiesta, il passaggio
avviene sfruttando il meccanismo di ritorno da interruzione.

\vspace{3mm}
Ad ogni processo è associata una pila (stack) gestita tramite il registro stack pointer. La pila rappresenta l'area di lavoro
del processo e contiene variabili temporanee ed i record di attivazione delle procedure chiamate.

\vspace{3mm}
I registri presenti sono: PC e PS (resgistro di stato), R1,...,Rn, R'1,...,R'n, SP1, SP1' (registri generali e stack pointer)
associati rispettivamente agli ambienti di nucleo e dei processi.

\vspace{3mm}
L'esecuzione di una primitiva da parte di P corrisponde all'esecuzione di una istruzione di tipo SVC:
\begin{enumerate}
    \item interruzione
    \item Salvataggio di PC e PS relativi a P in cima alla pila del nucleo
    \item Caricamento in PC e PS dell'indirizzo della procedura di risposta all'interruzione e di PS del nucleo
    \item Esecuzione della procedura di risposta all'interruzione con chiamata alla primitiva di nucleo richiesta (es P)
    \item P passante: esecuzzioen di ritorno dall'interruzione che ripristina in PC e PS i valori del processo contenuti nella pila del nucleo
    \item P bloccante (non passante): salvataggio stato
\end{enumerate}

\subsection{Architettura Multiprocessore: realizzazione del nucleo}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.60\columnwidth]{imgs/architettura.png}
\end{figure}

\vspace{3mm}
\textbf{Sistemi operativi multiprocessore: organizzazione interna}
\vspace{3mm}

Un sistema operativo che esegue su un'architettura multiprocessore deve gestire una molteplicità di CPU, ugnuna delle quali può accedere alla stessa memoria
condivisa.

Esistono principalmente due modelli:
\begin{itemize}
    \item \textbf{Modello SMP}: unica copia del nucleo condivisa tra tutte le CPU
    \item \textbf{Modello a nuclei distinti}: più istanze del nucleo concorrenti
\end{itemize}

\subsubsection{Modello SMP: Simmetric Multi Processing}

In questo modello è presente un'unica copia del nucleo del sistema operativo allocata nella memoria comune che si occupa della gestione di tutte le risorse
disponibili, comprese le CPU. Ogni processi può essere allocato su una qualunque CPU. Inoltre è possibile che processi che eseguono su CPU diverse
richiedano contemporaneamente funzioni del nucleo ad esempio le System Call. E dato che ogni funzione del nucleo comporta un accesso alle strutture
dati interne al nucleo, occore regolare gli accessi al nucleo in modo che avvengano in modo sincronizzato.

\vspace{3mm}
\textbf{Sincronizzazione nell'accesso al nucleo}:

\vspace{3mm}
\textbf{Soluzione ad un solo lock}:

Viene associato al nucleo \textbf{un Lock L}, per garantire la mutua esclusione nell'esecuzione di funzioni del nucleo da parte di processi diversi: l'accesso
esclusivo alle sue strutture dati può essere ottenuto delimitando il corpo di ogni richiesta per il nucleo con le primitive \textbf{lock} e \textbf{unlock}
applicate all'\textbf{unico Lock l}.

Il problema fondamentale di questa soluzione è la \textbf{limitazione del grado di parallelismo}, escludendo a priori ogni possibilità di esecuzione
contemporanea di funzioni del nucleo che operano su strutture dai distinte.

\vspace{3mm}
\textbf{Soluzione a più lock}:

Un maggiore parallelismo può essere ottenuto individuando all'interno del nucleo diverse classi di sezioni critiche, ognuna associata a una struttura dati
separata e sufficientemente indipendente dalle altre. Ad ogni struttura dati viene associato un lock distinto.

Ad esempio la coda dei processi pronti, i singoli semafori, ecc, vengono protetti tramite lock distinti.

Ogni operazionie del nucleo che richiederà l'accesso a una particolare struttura $$S_i$$ protetta dal locl $$L_i$$, conterrà una sezione critica
il cui prologo ed epilogo saranno rispettivamente $$lock(L_i)$$ e $$unlock(L_i)$$.

\vspace{3mm}
\textbf{Scheduling dei processi:}

Il modello SMP consente la schedulazione di ogni processo su uno qualunque dei processori attraverso la \textbf{load balancing}, ovvero la possibilità di
attuare politiche di distribuzione equa del carico sui processori.

Tuttavia, in alcuni casi può risultare più conveniente assegnare un processo ad un determinato processore:
\begin{itemize}
    \item i processori possono accedere più rapidaemnte alla loro memoria privata piuttosto che a quella remota, quindi potrebbe convenire schedulare il processo
    sul processore la cui memoria privata già contiene il suo codice.
    \item in sistemi NUMA l'accesso alla memoria "più vicina" è più rapido: conviene schedulare il processo sul processore più vicino alla memoria ove
    è allocato il suo spazio di indirizzamento
    \item i processori hanno memoria cache. Il processo dovrebbe essere assegnato al processore sul quale era stato precedentemente eseguito.
\end{itemize}

\subsubsection{Modello a nuclei distinti}

In questo modello la struttura interna del sistema operativo è articolata su più nucleo, ognuno dedicato alla gestione di una diversa CPU.

L'assunzione di base è che l'insieme dei processi che eseguiranno nel sistema sua partizionabile in tanti sottoinsiemi (nodi virtuali) lascamente connessi, cioè con un ridotto numero di
interazioni reciproche:
\begin{itemize}
    \item Ciascun nodo virtuale è associato ad un nodo fisico: esso è gestito da un nucleo distinto e pertanto tutte le strutture dati del nucleo relative al nodo virtuale vengono allocate
    sulla memoria privata del nodo fisico
    \item In questo modo tutte le interazioni locali al nodo virtuale possono avvenire indipendentemente e concorrentemente a quelle di altri nodi virtuali, facendo riferimento al nucleo del nodo.
\end{itemize}

\vspace{3mm}
Solo le interazioni tra processi appartenenti a nodi virtuali diversi utilizzano la memoria comune.

\subsubsection{Organizzazione SMP vs nuclei distinti}

\begin{itemize}
    \item \textbf{Grado di parallelismo tra CPU}: il modello a nuclei distinti è più vantaggioso, in quanto il grado di accoppiamento tra CPU è più basso. Maggiore scalabilità.
    \item \textbf{Gestione ottimale delle risorse computazionali}: 
    \begin{itemize}
        \item il modello SMP fornisce i presupposti per un migliore bilanciamento del carico tra le CPU perchè lo scheduler può decidere di allocare ogni processo su qualunque CPU.
        \item il secondo modello voncola ogni processo ad essere schedulato sempre sullo stesso nodo.
    \end{itemize}
\end{itemize}

\vspace{5mm}
\textbf{Realizzazione dei semafori nel modello SMP}

Tutte le CPU condividono lo stesso nucleo: per sincronizzare gli accessi al nucleo, le struttura dati del nucleo vengono protette tramite lock.

In particolare, i sinfoli semafori e la coda dei processi pronti vengono protetti tramite \textbf{lock distinti}.

In questo caso due operazioni P su semafori diversi:
\begin{itemize}
    \item possono operare in modo \textbf{contemporaneo} se non risultano sospensive
    \item in caso contrario, vengono \textbf{sequenzializzati} solo gli accessi alla coda dei processi pronti.
\end{itemize}


\newpackage


\section{Modello a scambio di messaggi}

Il modello architetturale di una macchina concorrente è caratterizzato da:
\begin{itemize}
    \item Ogni processo può accedere esclusivamente alle risorse allocate nella propria memoria locale.
    \item Ogni risorsa del sistema è accessibile direttamente ad un \textbf{solo processo (il Gestore della risorsa)}
    \item Se una risorsa è necessaria a più processi applicativi, ciascuno di questi (processi clienti) dovrà delegare l'unico processo che può operare sulla risorsa (processo server)
        all'esecuzione delle operazioni richieste; al termine di ogni operazione il server restituirà al cliente gli eventuali risultati
    \item In questo modello il concetto di \textbf{gestore} di una risorsa coincide con quello di processo server
    \item Ogni processo, per usifruire dei servizi offerti da una risorsa, dovrà comunicare con il gestore
    \item Il meccanismo di base utilizzato dai processi per qualunque tipo di interazione è costituito dal \textbf{meccanismo di scambio di messaggi}
\end{itemize}

\subsection{Canale di comunicazione}

Il concetto fondamentale del modello a scambio di messaggi è il \textbf{canale}, ovvero un \textbf{collegamento logico mediante il quale due o più processi comunicano}.

È il nucleo della macchina concorrente a realizzare l'astrazione "canale" come meccanismo primitivo per lo scambio di informazioni. Ed è compito del linguaggio di programmazione offrire
gli strumenti linguistici di alto livello per:
\begin{itemize}
    \item speficare i canali di comunicazione
    \item utilizzarli per esprimere le interazioni tra i processi
\end{itemize}

\vspace{5mm}
\textbf{Caratteristiche del canale di comunicazione}
\vspace{3mm}

I parametri che caratterizzano il concetto di canale sono:
\begin{itemize}
    \item la \textbf{direzione del flusso dei dati} che un canale può trasferire
    \item la \textbf{designazione del canale} e dei processi origine e destinatario di ogni comunicazione
    \item il tipo di \textbf{sincronizzazione} fra i processi comunicanti
\end{itemize}

\subsection{Tipi di Canali}

I canali possono essere distinti in più gruppi. Facendo riferimento alla \textbf{direzione del flusso dei dati}, possiamo distinguere due tipi di canali:
\begin{itemize}
    \item Canale \textbf{monodirezionale}: consente il flusso dei messaggi in una sola direzione (mittente verso ricevente)
    \item Canale \textbf{bidirezionale}: può essere usato sia per inviare che per ricevere informazioni
\end{itemize}

\vspace{3mm}
Facendo invece riferimento alla \textbf{designazione dei processi comunicanti}, è possibile definire tre tipi di canale:
\begin{itemize}
    \item \textbf{Link}: da uno-a-uno (canale simmetrico)
    \item \textbf{Port}: da molti-a-uno (canale asimmetrico)
    \item \textbf{Mailbox}: da molti-a-molti (canale asimmetrico)
\end{itemize}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.50\columnwidth]{imgs/link.png}
    \quad
    \includegraphics[width=0.50\columnwidth]{imgs/port.png}
\end{figure}

\vspace{3mm}
Con riferimento alla modalità di \textbf{sincronizzazione} tra i processi comunicanti, possiamo individuare tre tipi di canale:
\begin{itemize}
    \item Comunicazione \textbf{asincrona}
    \item Comunicazione \textbf{sincrona}
    \item Comunicazione con \textbf{sincronizzazione estesa}
\end{itemize}

\subsubsection{Comunicazione asincrona}

\textbf{Semantica}:

Il processo mittente \textbf{continua la sua esecuzione} immediatamente dopo l'invio del messaggio.

\vspace{3mm}
\textbf{Effetti}:

\begin{itemize}
    \item La ricezione del messaggio può avvenire in un istante successivo all'invio: il messaggio ricevuto contiene informazioni che non possono essere attribuite allo stato attuale del
        mittente e quindi c'è una difficoltà nella verifica dei programmi.
    \item L'invio di un messaggio non è un punto di sincronizzazione per mittente e destinatario.
\end{itemize}

\vspace{3mm}
\textbf{Proprietà}:

\begin{itemize}
    \item \textbf{Carenza espressiva}
    \item \textbf{L'assensa di vincoli di sincronizzazione} tra mittente e destinatario favorisce il \textbf{grado di concorrenza}
    \item Da un punto di vista realizzativo, sarebbe necessario un \textbf{buffer di capacità illimitata}
\end{itemize}

\vspace{3mm}
\textbf{Realizzazione}:

Ogni implementazione prevede inevitabilmente un limite alla capacità del buffer. Nel caso di un buffer pieno, se si vuole mantenere immutata la semantica, occorre che il supporto
a tempo di esecuzione provveda a sospendere il processo che invia il messaggio.

\subsubsection{Comunicazione Sincrona: rendez-vous semplice}

\textbf{Semantica}:

Il primo dei due processi comunicanti che esegue l'invio (mittente) o la ricezione (destinatario) si sospende in attesa che l'altro sia pronto ad eseguire l'operazione corrispondente.

\vspace{3mm}
\textbf{Effetti}:

L'invio di un messaggio è un \textbf{punto di sincronizzazione}: ogni messaggio rivcevuto contiene informazioni attribuibili allo stato attuale del processo mittente. Ciò semplifica la scrittura
e la verifica dei programmi.

\vspace{3mm}
Inoltre \textbf{non è necessaria l'introduzione di un buffer}: un messaggio può essere inviato solamente se il ricevente è pronto a riceverlo.

\vspace{5mm}
\textbf{Comunicazione asincrona vs sincrona}
\begin{itemize}
    \item L'invio con semantica sincrona è più espressivo
    \item La semantica asincrona consente di raggiungere maggiore concorrenza/parallelismo
    \item La realizzazione del canale nella comunicazione asincrona richiede opportuna struttura per l'accodamento dei messaggi.
\end{itemize}

\vspace{5mm}
\textbf{Comunicazione con sincronizzazione estesa: rendez-vous esteso}

\textbf{Assunzione}: ogni messaggio inviato rappresenta una richiesta al destinatario dell'esecuzione di una certa azione

\textbf{Semantica}: il processo mittente rimane in attesa fino a che il ricevente non ha terminato di svolgere l'azione richiesta


\subsection{Costrutti linguistici e primitice per esprimere la comunicazione}
\subsubsection{Definizione del canale (port)}

Un canale \textbf{port} identifica un canale asimmetrico \textbf{molti-a-uni}

port <tipo> <identificatore>;

\begin{lstlisting}
    port int ch1;
\end{lstlisting}

L'identificatore ch1 denota un canale utilizzato per trasferire messaggi di tipo intero. \textbf{Port} viene dichiarato locale ad un processo (il ricevente) ed è visibile ai
processi mittenti mediante la dot notation -> <nome_processo>.<identificatore_canale>

\subsubsection{Primitive di comunicazione sincrone}

\textbf{Send}
\vspace{3mm}

\textbf{Send} è la primitica che esprime l'invio di un messaggio:
\begin{center}
    send(<valore>) to <porta>;
\end{center}

\begin{itemize}
    \item \textbf{<porta>}: identifica in modo univoco il canale a cui inviare il messaggio;
    \item \textbf{<valore>}: identifica una espressione dello stesso tipo di <porta> e rappresenta il contenuto del messaggio inviato.
\end{itemize}

\vspace{3mm}
\textbf{Semantica}: può essere
\begin{itemize}
    \item \textbf{asincrona} -> canale bufferizzato;
    \item \textbf{sincrona} -> canale a capacità nulla;
\end{itemize}

A seconda della semantica e delle caratteristiche del canale la send può sospendere o meno il processo che la esegue. Ad esempio:
\begin{itemize}
    \item \textbf{Send sincrona}: il processo attende che il destinatario esegua la primitica di ricezione (receive) corrispondente;
    \item \textbf{Send asincrona}: il processo attende solo se il canale è pieno.
\end{itemize}

\vspace{5mm}
\textbf{Receive}
\vspace{3mm}

\begin{center}
    P = receive(<variabile>) from <porta>;
\end{center}

\begin{itemize}
    \item \textbf{<porta>}: identifica il \textbf{canale}, locale al processo ricevente, dal quale ricevere il messaggio;
    \item \textbf{<variabile>}: è l'identificativo della variabile, dello stesso tipo di <porta>, a cui assegnare il valore del messaggio ricevuto.
\end{itemize}

\vspace{3mm}
\textbf{Semantica}:
\begin{itemize}
    \item \textbf{Default: Semantica Bloccante}. La primirica sospende il processo se non ci sono messaggi sul canale; quando c'è almeno un messaggio nel canale, ne estrae il primo
        e ne assegna a <variabile> il valore. La receive restituisce un valore del tipo predefinito \textbf{process} che identifica il nome del processo mittente.
    \item Alcuni linguaggi offrono anche una semantica non bloccante: se il canale è vuoto, il processo continua; se contiene almeno un messaggio, estrae il primo e lo assegna a
        <variabile>.
\end{itemize}

\subsubsection{Receive Bloccante e Modello Client-Server}
Il \textbf{Server} è un processo che si occupa di servire le richieste di altri processi, detti \textbf{Client}. Il server ha la possibilità di eseguire diversi servizi, ognuno attivato in seguito
alla ricezione di un messaggio di tipo diverso. A questo scopo il server gestisce più \textbf{canali d'ingresso} (ad esempio porte), ognuno dedicato alla ricezione delle richieste di
un particolare servizio.

\vspace{3mm}
Il problema principale della recieve bloccante su un modello client-server sta nel fatto che il server specifica il canale sul quale eseguire ogni receive. Se i canali sono più di uno, il server
deve eseguire in sequenza le receie su ogni canale: poichè la receive ha semantica bloccante, c'è la possibilità di blocco su un canale mentre contemporaneamente ci sono messaggi in attesa di essere
ricevuti su altri canali.

\vspace{3mm}
Una possibile soluzione potrebbe essere una \textbf{receive con semantica non bloccante}: verifica lo stato del canale, restituisce un messaggio (se presente) o un'indicazione del canale vuoto
(non bloccante). Non sospende mai il processo che la esegue. Il server può eseguire un ciclo di ispezione/ricezione di/da tutti i canali.

In caso di presenza contemporanea di messaggi su più canali la scelta può essere fatta secondo diversi criteri oppure in modo non deterministico.

\textbf{Problema dell'attesa attiva}: se tutti i canali sono vuoti, il server continua a iterare.

\vspace{3mm}
\textbf{Meccanismo di ricezione ideale}:
\begin{itemize}
    \item consente al processo server di verificare contemporaneamente la disponibilità di messaggi su più canali;
    \item abilità di ricezione di un messaggio da un qualunque canale contenente messaggi;
    \item quando tutti i canali sono vuoti, blocca il processo in attesa che arrivi un messaggio, qualunque sia il canale su cui arriva.
\end{itemize}

Questo meccanismo è realizzabile tramite i \textbf{comandi con guardia}.

\subsubsection{Comandi con Guardia}

\begin{center}
$<$\textbf{gaurdia}$>$ -$>$ $<$\textbf{istruzione}$>$
\end{center}

dove \textbf{guardia} è costituita dalla coppia: \textbf{(espressione booleana; receive)}
\begin{itemize}
    \item \textbf{espressione booleana} viene detta guardia logica;
    \item \textbf{receive} con semantica bloccante e viene detta guardia d'ingresso;
\end{itemize}

\vspace{5mm}
\textbf{Valutazione della guardia}

\vspace{3mm}
\begin{center}
$<$guardia$>$ := ($<$espressione booleana$>$; $<$receive$>$)
\end{center}

La valutazione della guardia può fornire tre diversi valori:
\begin{itemize}
    \item \textbf{guardia fallita}: se l'espressione ha valore false e il comando eseguito con guardia fallisce;
    \item \textbf{guardia ritardata}: se l'espressione booleana ha valore true e nel canale su cui viene eseguita non ci sono messaggi, il processo che esegue il comando viene sospenso
        e quando arriverà il primo messaggio nel canale riferito dalla guardia d'ingressom il processo verrà riattivato, eseguirà la receive e successivamente l'istruzione;
    \item \textbf{guardia valida}: se l'espressione booleana ha valore true e nel canale c'è almeno un messaggio, quindi il processo esegue la receive e successivamente l'istruzione.
\end{itemize}

\vspace{5mm}
\textbf{Comando con guardia alternativo}

\vspace{3mm}

\begin{lstlisting}
select {
    [] <guardia_1> -> <istruzione_1>;
    ...
    [] <guardia_n> -> <istruzione_n>;
}
\end{lstlisting}

Il comando con guardia alternativo (select) racchiude un numero arbitrario di comandi con guardia semplici.

Vengono valutate le guardie di tutti i rami e si possono verificare 3 casi:
\begin{itemize}
    \item \textbf{se una o più guardie sono valide}: viene scelto, in maniera non deterministica, uno dei rami con guardia valida e la relativa guardia viene eseguita, viene quindi eseguita
    l'istruzione relativa al ramo scelto, e con ciò termina l'esecuzione dell'intero comando alternativo;
    \item \textbf{se tutte le guardie non fallite sono ritardate}: il processo in esecuzione si sospende in attesa che arrivi un messaggio che abilita la transizione di una guardia da
    ritardata a valida e a quel punto procede come nel caso precedente;
    \item \textbf{se tutte le guardie sono fallite}: il comando termina.
\end{itemize}

\vspace{5mm}
\textbf{Comando con guardia ripetitivo}

\vspace{3mm}

\begin{lstlisting}
do {
    [] <guardia_1> -> <istruzione_1>;
    ...
    [] <guardia_n> -> <istruzione_n>;
}
\end{lstlisting}

Vengono valutate le guardie di tutti i rami e si possono verificare 3 casi:
\begin{itemize}
    \item \textbf{se una o più guardie sono valide}: viene scelto in maniera non deterministica uno dei rami con guardia valida e la relativa guardia viene eseguita, viene quindi eseguita
    l'istruzione relativa al ramo scelto, e poi si passa al ciclo successivo (ripetizione);
    \item \textbf{se tutte le guardie non fallite sono ritardate}: il processo in esecuzione si sospende in attesa che arrivi un messaggio che abilita la transizione da una guardia ritardata
    a valida; e a quel punto procede come nel caso precedente (si itera);
    \item \textbf{se tutte le guardie sono fallite}: l'esecizione del comando termina.
\end{itemize}

\subsubsection{Primitive di comunicazione asincrone}

Nel modello a scambio di messaggi, lo strumento di comunicazione di più basso livello è la \textbf{send asincrona}. Nel quale ad ogni operazione associata alla risorsa corrisponde
un diverso servizio.

\vspace{3mm}
\textit{Accesso a risorse "condivise" -> processi servitori}

\vspace{3mm}

Verranno ora analizzate delle \textbf{soluzioni di problemi di sicronizzazioen con send asicrona}.

Prendendo in considerazioen alcuni tipici problemi di interazione nel modello a scambio di messaggi. Quindi ci si chiede: data una risorsa, come implementare nel modello a scambio
di messaggi (con send asincrona) il gestore della risorsa nel caso in cui sia previsto:
\begin{itemize}
    \item una sola operazione;
    \item più operazioni mutuamente esclusive;
    \item più operazini con condizioni di sincronizzazione.
\end{itemize}

\vspace{5mm}
{\large \textbf{1. Risorsa condivisa con una sola operazione}}

\vspace{3mm}
Risorsa condivisa che mette a disposizioen di un insieme di processi "clienti" una sola operazione con il solo vincolo della mutua esclusione.

\vspace{3mm}
\textbf{Soluzione nel modello a memoria comune}: il gestore è un \textbf{monitor} con \textbf{una operazioen entry}

\noindent
\begin{minipage}{.45\columnwidth}
\begin{lstlisting}
monitor gestore {
    tipo_var var;
    <eventuale inizializzazione>;
    entry tipo_out fun(tipo_in x) {
        <corpo della funzione fun>;
    }
}

gestore ris; // istanza del gestore
\end{lstlisting}
\end{minipage}\hfill
\begin{minipage}{.45\columnwidth}
\begin{lstlisting}
thread client {
    tipo_in a;
    tipo_out b;

    b = ris.fun(a);
}
\end{lstlisting}
\end{minipage}

\vspace{3mm}
\textbf{Soluzione nel modello a scambio di messaggi}:

La risorsa viene gestita da un \textbf{processo server} che offre un unico servizio senza condizioni di sincronizzazione.

\noindent
\begin{minipage}{.45\columnwidth}
\begin{lstlisting}
// cliente: un solo canale risposta di tipo tipo_out

process cliente {
    port tipo_out risposta;
    tipo_in a;
    tipo_out b;
    process p;
    ...
    send(a) to server.input;
    p = receive(b) from risposta;
    ...
}
\end{lstlisting}
\end{minipage}\hfill
\begin{minipage}{.45\columnwidth}
\begin{lstlisting}
// server: un solo canale input di tipo tipo_in

tipo_out fun(tipo_in x);

process server {
    port tipo_in input;
    tipo_var var;
    process p;
    tipo_in x;
    tipo_out y;
    <eventuale inizializzazione>;
    while(true) {
        p = receive(x) from input;
        y = fun(x);
        send(y) to p.risposta;
    }
}
\end{lstlisting}
\end{minipage}

\vspace{5mm}
{\large \textbf{2. Risorsa condivisa con più operazioni}}

\vspace{3mm}
Risorsa condivisa che mette a disposizione di un insieme di processi clienti due operazioni con il solo vincolo della mutua esclusione.

\vspace{3mm}
\textbf{Soluzione nel modello a memoria comune}: il gestore è un monitor con \textbf{due operazioni entry}:

\noindent
\begin{minipage}{.45\columnwidth}
\begin{lstlisting}
monitor gestore {
    tipo_var var;
    ...
    entry tipo_out1 fun1(tipo_in1 x1) {
        <corpo della funzione fun1>;
    }
    entry tipo_out2 fun2(tipo_in2 x2) {
        <corpo della funzione fun2>;
    }
}

gestore ris;
\end{lstlisting}
\end{minipage}\hfill
\begin{minipage}{.45\columnwidth}
\begin{lstlisting}
thread client {
    tipo_in1 a1;
    tipo_in2 a2;
    tipo_out1 b1;
    tipo_out2 b2;
    ...
    b1 = ris.fun1(a1);
    ...
    b2 = ris.fun2(a2);
}
\end{lstlisting}
\end{minipage}

\vspace{3mm}
\textbf{Soluzione nel modello a scambio di messaggi}:

La risorsa è gestita da un processo servitore che offre 2 servizi senza condizioni di sincronizzazione.

\begin{itemize}
    \item soluzione senza comandi con guardia: un solo canale per entrambi i tipi di richiesta. [codice]
    \item Soluzione con comandi con guardia: per ogni servizio il server apre un canale distinto. [codice]
\end{itemize}

\vspace{5mm}
{\large \textbf{3. Risorsa condivisa con più operazioni e condizioni di sincronizzazione}}

\vspace{3mm}
La risorsa è gestita da un processo servitore che offre \textbf{due operazioni di sincronizzazione}

\vspace{3mm}
\textbf{Soluzione nel modello a memoria comune}: la risorsa è gestita da un monitor con 2 entry e 2 variabili condizione

\begin{lstlisting}
condition c1, c2;
\end{lstlisting}
\noindent
\begin{minipage}{.45\columnwidth}
\begin{lstlisting}
entry tipo_out1 op1(tipo_in1 x1) {
    ...
    if(!cond1)
        wait(c1);
    ...
    signal(c2);
    ...
}
\end{lstlisting}
\end{minipage}\hfill
\begin{minipage}{.45\columnwidth}
\begin{lstlisting}
entry tipo_out2 op2(tipo_in2 x2) {
    ...
    if(!cond2)
        wait(c2);
    ...
    signal(c1);
    ...
}
\end{lstlisting}
\end{minipage}

\vspace{3mm}
\textbf{Soluzione nel modello a scambio di messaggi}:

La risorsa è gestita da \textbf{un processo servitore con due servizi}:
\begin{itemize}
    \item viene associato ad ogni servizio un canale distinto;
    \item la ricezione delle richieste in arrivo viene realizzata con un \textbf{comando con guardia ripetitivo}, con due rami (uno per servizio); in ogni ramo la
    \textbf{guardia logica} esprime la \textbf{condizione di sincronizzazione}
\end{itemize}

\begin{lstlisting}
tipo_out1 fun1(tipo_in1 x1);
tipo_out2 fun2(tipo_in2 x2);

process server {
    port tipo_in1 input1;
    port tipo_in2 input2;
    tipo_var var;
    tipo_in1 x1;
    tipo_in2 x2;
    tipo_out1 y1;
    tipo_out2 y2;
    ...
    do {
        [] (cond1);
            p = receive (x1) from input1; -> {
                y1 = fun1(x1);
                send(y1) to p.risposta1;
            }
        [] (cond2);
            p = receive (x2) from input2; -> {
                y2 = fun2(x2);
                send (y2) to p.risposta2;
            }
    }
}
\end{lstlisting}

\vspace{3mm}
\textbf{Corrispondenza tra monitor e processi servitori}
\begin{center}
\begin{tabular}{||p{6cm}|p{6cm}||}
    \hline
    \textbf{Modello a memoria comune} & \textbf{modello a scambio di messaggi} \\
    \hline
    \textbf{risorsa condivisa}: istanza di un monitor & \textbf{risorsa condivisa}: struttura dati locale a un processo server \\
    \hline
    identificatore di funzione di accesso al monitor & porta del processo server \\
    \hline
    tipo dei parametri della funzione & tipo della porta \\
    \hline
    tipo del valore restituito dalla funzione & tipo della porta da cui il processo cliente rivece il risultato \\
    \hline
    per ogni funzione del monitor & un ramo (comando con guardia) dell'istruzione ripetitiva che costituisce il corpo del server \\
    \hline
    condizione di sincronizzazione di una funzione entry & guardia logica componente del ramo corrispondente alla funzione \\
    \hline
    chiamata di funzione entry & invio (send) della richiesta sulla corrispondente porta del server e attesa (receive) dei risultati sulla propria porta \\
    \hline
    esecuzione in mutua esclusione fra le chiamate alle funzioni del monitor & scelta di uno dei rami con guardia valida del comando ripetitivo del server \\
    \hline
    corpo della funzione & istruzione del ramo corrispondente alla funzione \\
    \hline
\end{tabular}
\end{center}



\end{document}
