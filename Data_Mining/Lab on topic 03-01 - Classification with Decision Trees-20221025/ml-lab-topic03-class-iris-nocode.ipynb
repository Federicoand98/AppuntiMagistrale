{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<!--BOOK_INFORMATION-->\n",
    "*This notebook contains an excerpt from the <a href=\"http://shop.oreilly.com/product/0636920034919.do\">Python Data Science Handbook</a> by Jake VanderPlas; the content is available on <a href=\"https://github.com/jakevdp/PythonDataScienceHandbook\">GitHub</a>.*\n",
    "\n",
    "*The text is released under the [CC-BY-NC-ND license](https://creativecommons.org/licenses/by-nc-nd/3.0/us/legalcode), and code is released under the [MIT license](https://opensource.org/licenses/MIT). If you find this content useful, please consider supporting the work by [buying the book](http://shop.oreilly.com/product/0636920034919.do)!*\n",
    "\n",
    "Adapded for class presentation by Claudio Sartori - University of Bologna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introducing Scikit-Learn\n",
    "\n",
    "<a href=\"http://scikit-learn.org\">Scikit-Learn</a>\n",
    "- package that provides efficient versions of a large number of common algorithms\n",
    "- clean, uniform, and streamlined API\n",
    "- very useful and complete online documentation.\n",
    "    - once you understand the basic use and syntax of Scikit-Learn for one type of model, switching to a new model or algorithm is very straightforward\n",
    "    \n",
    "## Contents\n",
    "\n",
    "- *Introduction* to Scikit-Learn\n",
    "- *Data representation* in Scikit-Learn\n",
    "- *Estimator* API\n",
    "- *Examples*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Representation in Scikit-Learn\n",
    "\n",
    "### Data as table\n",
    "\n",
    "- a two-dimensional grid of data\n",
    "    - rows represent individual elements of the data set\n",
    "    - columns represent quantities related to each of these elements\n",
    "\n",
    "- Example: [Iris dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set)\n",
    "    - analyzed by Ronald Fisher in 1936\n",
    "    - download this dataset in the form of a Pandas ``DataFrame`` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the __Iris__ dataset at the url `https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data` or from your local file, if you already have it. The file does not have header, use as column names the list below,  inspect the text file to see which character is used as separator.\n",
    "\n",
    "`'sepal length', 'sepal width', 'petal length', 'petal width', 'species'`\n",
    "\n",
    "Use the dataframe name `iris`. Show the head of `iris`\n",
    "\n",
    "As an alternative way of loading the data, you can use [this utility](https://scikit-learn.org/stable/datasets/index.html) included in scikit-learn\n",
    "\n",
    "--> Insert your code in new cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- each row refers to a single observed flower\n",
    "    - the number of rows is the total number of flowers in the dataset.\n",
    "    - *sample*: a single row\n",
    "    - ``n_samples``: number of rows\n",
    "\n",
    "- each column refers to a piece of information that describes each sample\n",
    "    - *feature*: a single column\n",
    "    ``n_features``: the number of columns\n",
    "        - each column has a data type: number (continuous), boolean, discrete (nominal or ordinal, represented with integers or strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Features matrix\n",
    "\n",
    "The part of the data matrix containing the ``unsupervised attributes``\n",
    "\n",
    "Usually in *scikit-learn* documentation referred as ``X``\n",
    "\n",
    "Can be a:\n",
    "- two-dimensional numpy array with shape ``[n_samples, n_features]``\n",
    "- SciPy ``sparse matrix``\n",
    "- Pandas ``DataFrame``\n",
    "\n",
    "The matrix cases require uniform data types in columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Target array\n",
    "\n",
    "*label* or *target* array, by convention usually called ``y``\n",
    "- usually one dimensional, with length ``n_samples``, \n",
    "- generally contained in a NumPy array or Pandas ``Series``.\n",
    "- may have continuous numerical values, or discrete classes/labels\n",
    "- usually it the quantity we want to *predict from the data*\n",
    "    - in statistical terms, it is the dependent variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In the example we may wish to construct a model that can predict the species of flower based on the other measurements\n",
    "\n",
    "The measurements of the flower components are the ``features array``\n",
    "\n",
    "The ``species`` column can be considered the target array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Visualization\n",
    "\n",
    "Use Seaborn (see [Visualization With Seaborn](04.14-Visualization-With-Seaborn.ipynb)) to visualize the data\n",
    "\n",
    "Below we need to prepare the environment for plotting information on the dataset.\n",
    "\n",
    "1. issue the command `%matplotlib inline` In this way, the output of plotting commands is displayed inline within frontends like the Jupyter notebook, directly below the code cell that produced it. The resulting plots will then also be stored in the notebook document.\n",
    "2. import `seaborn` giving it the 'nickname' `sns`\n",
    "3. call the `pairplot` function of `seaborn` on the `iris` dataset, with parameters \n",
    "    - `hue = 'species'`, this sets the meaning of the color in the plot of the points of the dataset\n",
    "    - `height = 2`, this sets the size of the plots\n",
    "    \n",
    "--> insert your code in a new cell below this one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "For use in Scikit-Learn, we will extract the features matrix and target array from the ``DataFrame``. We can do this using some of the Pandas ``DataFrame`` operations discussed in the [Chapter 3](https://jakevdp.github.io/PythonDataScienceHandbook/03.00-introduction-to-pandas.html) of the above mentioned book.\n",
    "\n",
    "For example, the `.drop` method allows to drop a column or row by name; remember to specify the axis to use, which is 1 for columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Preparing features and target\n",
    "Store in X the content of `iris` excluding the column `species`. Verify the shape\n",
    "\n",
    "--> insert your code in a new cell below this one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store in `y` the column `species` of `iris`. Verify the shape\n",
    "\n",
    "--> insert your code in a new cell below this one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To summarize, the expected layout of features and target values is visualized in the following diagram:\n",
    "![Figure](figures/05.02-samples-features.png \"Features and target\")\n",
    "With this data properly formatted, we can move on to consider the estimator API of Scikit-Learn:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Scikit-Learn's Estimator API\n",
    "\n",
    "The Scikit-Learn API is designed with the following guiding principles in mind, as outlined in the [Scikit-Learn API paper](http://arxiv.org/abs/1309.0238):\n",
    "\n",
    "- *Consistency*: All objects share a common interface drawn from a limited set of methods, with consistent documentation.\n",
    "\n",
    "- *Inspection*: All specified parameter values are exposed as public attributes.\n",
    "\n",
    "- *Limited object hierarchy*: Only algorithms are represented by Python classes; datasets are represented\n",
    "  in standard formats (NumPy arrays, Pandas ``DataFrame``s, SciPy sparse matrices) and parameter\n",
    "  names use standard Python strings.\n",
    "\n",
    "- *Composition*: Many machine learning tasks can be expressed as sequences of more fundamental algorithms,\n",
    "  and Scikit-Learn makes use of this wherever possible.\n",
    "\n",
    "- *Sensible defaults*: When models require user-specified parameters, the library defines an appropriate default value.\n",
    "\n",
    "In practice, these principles make Scikit-Learn very easy to use, once the basic principles are understood.\n",
    "Every machine learning algorithm in Scikit-Learn is implemented via the Estimator API, which provides a consistent interface for a wide range of machine learning applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "The machine learning algorithms are designed to learn from the data the _parameters_ that will be used at run time by the algorithms implementing the tasks to perform at the best on data similar to those used in learning. \n",
    "\n",
    "For example, a _decision tree_ (and in particular all the tests placed in the nodes) are the parameters of a _decision tree classifier_\n",
    "\n",
    "The learning process is also controlled by other parameters (e.g. to control the _overfitting_ ) which cannot be direcly learned from the data, but are chosen _before_ the learning process. Those are called __hyperparameters__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Basics of the API\n",
    "\n",
    "Most commonly, the steps in using the Scikit-Learn estimator API are as follows\n",
    "(we will step through a handful of detailed examples in the sections that follow).\n",
    "\n",
    "1. Choose a class of model by importing the appropriate estimator class from Scikit-Learn.\n",
    "2. Choose model hyperparameters by instantiating this class with desired values.\n",
    "    - or in the first attempt use the default values\n",
    "3. Arrange data into a features matrix and target vector following the discussion above.\n",
    "4. Fit the model to your data by calling the ``fit()`` method of the model instance.\n",
    "5. Apply the Model to new data:\n",
    "   - For supervised learning, often we predict labels for unknown data using the ``predict()`` method.\n",
    "   - For unsupervised learning, we often transform or infer properties of the data using the ``transform()`` or ``predict()`` method.\n",
    "\n",
    "We will now step through several simple examples of applying supervised and unsupervised learning methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Supervised learning example: Iris classification\n",
    "\n",
    "Let's take a look at another example of this process, using the Iris dataset we discussed earlier.\n",
    "Our question will be this: given a model trained on a portion of the Iris data, how well can we predict the remaining labels?\n",
    "\n",
    "For this task, we will use the _Decision Tree_ algorithm, with the standard parameter values.\n",
    "We would like to evaluate the model on data it has not seen before, and so we will split the data into a *training set* and a *testing set*.\n",
    "This could be done by hand, but it is more convenient to use the ``train_test_split`` utility function\n",
    "\n",
    "1. Import the method `train_test_split` from `sklearn.model_selection`<br>\n",
    "2. Generate the variables `Xtrain, Xtest, ytrain, ytest` by calling the function `train_test_split` with parameters `X` and `y`, and the additional parameter `random_state = 1`<br>\n",
    "3. Show the shape of the resulting variables<br>\n",
    "\n",
    "\n",
    "--> insert your code in a new cell below this one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "With the data arranged, we can follow our recipe to predict the labels:\n",
    "1. choose the model class, it will be `DecisionTreeClassifier`, imported from `sklearn.tree`<br>\n",
    "2. instantiate the `model` as a `DecisionTreeClassifier` whithout any hyperparameter, we will use the defaults<br>\n",
    "3. fit the `model` to data, calling its method `fit` with parameters `Xtrain, ytrain`<br>\n",
    "4. predict the target `ytrain_model` using the `predict` method of `model` on the `Xtrain` data\n",
    "\n",
    "--> insert your code in a new cell below this one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can use the ``accuracy_score`` utility to see the fraction of predicted training set labels that match their true value.\n",
    "\n",
    "Import the `accuracy_score` from `sklearn.metrics` and call it on `ytrain, ytrain_model`\n",
    "\n",
    "--> insert your code in a new cell below this one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Finally, predict the new target `ytest_model` using the `predict` method of `model` on the `Xtest` data, then compute the accuracy on the test set\n",
    "\n",
    "--> insert your code in a new cell below this one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the Decision Tree\n",
    "To show the Decision Tree we will need a few imports\n",
    "\n",
    "`from matplotlib import pyplot`<br>\n",
    "`from sklearn.tree import plot_tree`<br>\n",
    "`from matplotlib.pyplot import figure`\n",
    "\n",
    "We will start setting the _figure size_ with the `figure` function, taking as argument `figsize` and a list of two values in inches, try and error for the measures you like.\n",
    "\n",
    "We will then use the `plot_tree` function of `sklearn.tree`. It takes as argument the *fitted model*\\, in our case `model` and several arguments to control how the tree is displayed.\n",
    "\n",
    "I suggest the arguments below, you can try freely configurations and omissions of the parameters, to use the defaults. The parameters must follow the model variable and be separated by commas, the order is not relevant, since the parameters are named.\n",
    "\n",
    "`filled=True` \\\n",
    "`feature_names = ['sepal length', 'sepal width', 'petal length', 'petal width']` \\\n",
    "`class_names = ['setosa', 'versicolor', 'virginica']` \\\n",
    "`rounded = True`\\\n",
    "`proportion = True`\\\n",
    "`rotate = False`\n",
    "\n",
    "--> insert your code in a new cell below this one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3.10.2 ('mypython')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "856490cdf840ba517e6730ee923aec993854a2ac7b35c746552be6a833f388f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
